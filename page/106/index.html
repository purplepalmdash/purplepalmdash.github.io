<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/12/06/tipsoncassandraonkubernetes/>TipsOnCassandraOnKubernetes</a></h1><span class=post-date>Dec 6, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>First download the image from gcr.io:</p><pre><code>$ sudo docker pull gcr.io/google-samples/cassandra:v11
</code></pre><p>Create a replicas using following yaml file:</p><pre><code>apiVersion: v1
kind: ReplicationController
metadata:
  name: cassandra
  # The labels will be applied automatically
  # from the labels in the pod template, if not set
  # labels:
    # app: cassandra
spec:
  replicas: 1
  # The selector will be applied automatically
  # from the labels in the pod template, if not set.
  # selector:
      # app: cassandra
  template:
    metadata:
      labels:
        app: cassandra
    spec:
      containers:
        - command:
            - /run.sh
          resources:
            limits:
              cpu: 0.5
          env:
            - name: MAX_HEAP_SIZE
              value: 512M
            - name: HEAP_NEWSIZE
              value: 100M
            - name: CASSANDRA_SEED_PROVIDER
              value: &quot;io.k8s.cassandra.KubernetesSeedProvider&quot;
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          image: gcr.io/google-samples/cassandra:v11
          name: cassandra
          ports:
            - containerPort: 7000
              name: intra-node
            - containerPort: 7001
              name: tls-intra-node
            - containerPort: 7199
              name: jmx
            - containerPort: 9042
              name: cql
          volumeMounts:
            - mountPath: /cassandra_data
              name: data
      volumes:
        - name: data
          emptyDir: {}
</code></pre><p>Create rc:</p><pre><code>$ kubectl create -f cassandra-controller.yaml
</code></pre><p>Also create a service using following yaml definition:</p><pre><code>apiVersion: v1
kind: Service
metadata:
  labels:
    app: cassandra
  name: cassandra
spec:
  clusterIP: None
  ports:
    - port: 9042
  selector:
    app: cassandra
</code></pre><p>Start the service via:</p><pre><code>$ kubectl create -f cassandra-service.yaml 
</code></pre><p>Now scale the replica via:</p><pre><code>$  kubectl scale rc cassandra --replicas=2 
replicationcontroller &quot;cassandra&quot; scaled
</code></pre><p>Get the pods name and docker exec the command <code>nodetool status</code> to view the cassandra cluster status:</p><pre><code> kubectl exec -ti cassandra-0px0a -- nodetool status
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack
UN  172.17.0.5  65.61 KiB  32           100.0%            fe61ce57-2a8b-462c-8fbf-12c69461f17c  rack1
UN  172.17.0.6  84.76 KiB  32           100.0%            c9b78b8c-f207-41f8-b3f7-d962dbebe687  rack1
</code></pre><p>Now scale the replicas to 4 and examine the result:</p><pre><code>$ kubectl scale rc cassandra --replicas=4            
replicationcontroller &quot;cassandra&quot; scaled
$ kubectl exec -ti cassandra-0px0a -- nodetool status
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address     Load       Tokens       Owns (effective)  Host ID                               Rack
UN  172.17.0.5  65.61 KiB  32           50.8%             fe61ce57-2a8b-462c-8fbf-12c69461f17c  rack1
UN  172.17.0.7  48.33 KiB  32           40.0%             2b9fcbed-e737-496e-b960-d3d32b3091f5  rack1
UN  172.17.0.6  84.76 KiB  32           55.4%             c9b78b8c-f207-41f8-b3f7-d962dbebe687  rack1
UN  172.17.0.8  58.09 KiB  32           53.8%             5ba29b11-7366-48d8-b3ed-ddefbd6f2e28  rack1
</code></pre><p>See now you could play happily with cassandra on kubernetes.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/11/30/buildcollectdforxenserver/>BuildCollectdForXenServer</a></h1><span class=post-date>Nov 30, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=先决条件>先决条件</h3><p>启用aliyun CentOS源，安装工具:</p><pre><code>$ yum install rpm-build --skip-broken
</code></pre><p>因为编译可能会占用大量硬盘空间，预先加载某个NFS卷:</p><pre><code># mount -t nfs 192.168.0.221:/xxxx /mnt
</code></pre><p>下载源码包:</p><p>错误！！！ rpm-build安装失败。</p><p>不建议在xenserver上手动编译，上网搜索，找到collectd正确的源:</p><pre><code># vim /etc/yum.repos.d/collectd-ci.repo
[collectd-ci]
name=collectd CI
baseurl=http://pkg.ci.collectd.org/rpm/collectd-5.5/epel-5-$basearch
enabled=1
gpgkey=http://pkg.ci.collectd.org/pubkey.asc
gpgcheck=0
repo_gpgcheck=0
# yum remove collectd &amp;&amp; yum install -y collectd
</code></pre><h3 id=trouble-shooting>Trouble-Shooting</h3><p>如果激活有其他源，则可能会因为优先级顺序，优先安装例如epel里的collectd-i386之类的包，
解决方案是将这些源全盘屏蔽。</p><pre><code>[root@xenserver-WolfHunter yum.repos.d]# ls
back  Citrix.repo  collectd-ci.repo
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/11/30/minikubemyblog/>MinikubeMyBlog</a></h1><span class=post-date>Nov 30, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=generate-blog>Generate blog</h3><p>Generate the static blog via:</p><pre><code># hugo --theme=hyde-a
</code></pre><h3 id=persist-volume>Persist Volume</h3><p>Define a pv:</p><pre><code>$ vim blog.yaml
kind: PersistentVolume
apiVersion: v1
metadata:
  name: pvblog
  labels:
    type: local
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &quot;/data/hugoblog&quot;
</code></pre><p>Create this pv:</p><pre><code>$ kubectl create -f blog.yaml
persistentvolume &quot;pvblog&quot; created
</code></pre><p>Create a pv claim:</p><pre><code>$ vim blogclaim.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: blogclaim
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi
</code></pre><p>Create this pv claim:</p><pre><code>$ kubectl create -f ./blogclaim.yaml
persistentvolumeclaim &quot;blogclaim&quot; created
</code></pre><p>Examine the result:</p><pre><code>$ kubectl get pv
NAME      CAPACITY   ACCESSMODES   STATUS    CLAIM               REASON    AGE
pvblog    5Gi        RWO           Bound     default/blogclaim             4m
$ kubectl get pvc
NAME        STATUS    VOLUME    CAPACITY   ACCESSMODES   AGE
blogclaim   Bound     pvblog    5Gi        RWO           2m
</code></pre><p>Upload your blog website into <code>/data/hugoblog</code>.</p><p>Create a pod definition:</p><pre><code>$ vim hugo.yaml
kind: Pod
apiVersion: v1
metadata:
  name: hugoblog
  labels:
    name: hugoblog
spec:
  containers:
    - name: hugocontainer
      image: nginx
      imagePullPolicy: IfNotPresent
      ports:
        - containerPort: 80
          name: &quot;http-server&quot;
      volumeMounts:
      - mountPath: &quot;/usr/share/nginx/html&quot;
        name: pvblog
  volumes:
    - name: pvblog
      persistentVolumeClaim:
       claimName: blogclaim
</code></pre><p>Creat this pod via:</p><pre><code>$ kubectl create -f hugo.yaml
pod &quot;hugoblog&quot; created
$ kubectl get pod
NAME       READY     STATUS    RESTARTS   AGE
hugoblog   1/1       Running   0          &lt;invalid&gt;
</code></pre><p>Expose service:</p><pre><code>$ vim nginx.json
{
  &quot;kind&quot;: &quot;Service&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    &quot;name&quot;: &quot;frontendservice&quot;
  },
  &quot;spec&quot;: {
    &quot;ports&quot;: [
      {
        &quot;protocol&quot;: &quot;TCP&quot;,
        &quot;port&quot;: 3000,
        &quot;targetPort&quot;: &quot;http-server&quot;
      }
    ],
    &quot;type&quot;: &quot;LoadBalancer&quot;,
    &quot;selector&quot;: {
      &quot;name&quot;: &quot;hugoblog&quot;
    }
  }
}
</code></pre><p>Creat the service via this json file:</p><pre><code>$ kubectl create -f nginx.json
</code></pre><p>Get the service status, and access it via minikube command:</p><pre><code>$  kubectl get service
NAME              CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
frontendservice   10.0.0.217   &lt;pending&gt;     3000/TCP   2m
kubernetes        10.0.0.1     &lt;none&gt;        443/TCP    1d
$ minikube service frontendservice --url
http://192.168.99.101:31521
</code></pre><p>Open your browser and navigate to the corresponding url then you could get the
website running.</p><h3 id=port-forward>port-forward</h3><p>Use following command, forward the local flows to pod:</p><pre><code>$ kubectl port-forward hugoblog 8078:80
</code></pre><p>Now open your browser visit <code>http://localhost:8078</code>, then you could visit the
blog.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/11/28/runwordpressonminikube/>RunWordPressOnMinikube</a></h1><span class=post-date>Nov 28, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=installation>Installation</h3><p>On Ubuntu16.04, first download the deb package from</p><p><a href=https://github.com/kubernetes/minikube/releases>https://github.com/kubernetes/minikube/releases</a></p><p>Install virtualbox:</p><pre><code>$ sudo apt-get install -y virtualbox
$ sudo dpkg -i minikube_0.12-2.deb
$ which minikube-linux-amd64 
/usr/bin/minikube-linux-amd64
</code></pre><h3 id=start-cluster>Start Cluster</h3><p>First install kubectl:</p><pre><code>$ curl -Lo kubectl \
https://storage.googleapis.com/kubernetes-release/release/v1.3.0/bin/linux/amd64/kubectl \
&amp;&amp; chmod +x kubectl &amp;&amp; sudo mv kubectl /usr/local/bin/
</code></pre><p>Start kubernetes cluster via:</p><pre><code>$ minikube-linux-amd64 start
Starting local Kubernetes cluster...
Downloading Minikube ISO
 36.00 MB / 36.00 MB [==============================================] 100.00%
0s
Kubectl is now configured to use the cluster.
</code></pre><p>Examine the result:</p><pre><code>$ kubectl get pods --all-namespaces
NAMESPACE     NAME                          READY     STATUS RESTARTS   AGE
kube-system   kube-addon-manager-minikube   0/1       ContainerCreating   0	1m
</code></pre><p>Examine the status:</p><pre><code>$ minikube-linux-amd64 status
minikubeVM: Running
localkube: Running
</code></pre><p>View add-on lists:</p><pre><code>$ minikube addons list
- heapster: disabled
- ingress: disabled
- registry-creds: disabled
- addon-manager: enabled
- dashboard: enabled
- kube-dns: enabled
</code></pre><p>Trouble-Shooting:<br>When getting following error msgs, delete <code>~/.minikube</code> and run <code>minikube start</code> again solves the problem.</p><pre><code>~$ minikube start
Starting local Kubernetes cluster...
E0224 15:08:58.755236    7977 start.go:107] Error starting host: Error getting state for host: machine does not exist.
</code></pre><h3 id=minikube-upgrade>minikube upgrade</h3><p>Upgrade minikube in ubuntu by installing the newest deb package.</p><p>Upgrade minikube in ArchLinux by <code>yaourt -S minikube</code>, then <code>minikube start</code>
will use the newest version.</p><h3 id=trouble-shooting-in-dashboard>Trouble-Shooting In Dashboard</h3><p>When startup the dashboard, the minikube will complains could not find the endpoint:</p><pre><code>$ minikube-linux-amd64 dashboard
Could not find finalized endpoint being pointed to by kubernetes-dashboard: Temporary Error: endpoints &quot;kubernetes-dashboard&quot; not found
Temporary Error: endpoints &quot;kubernetes-dashboard&quot; not found
Temporary Error: endpoints &quot;kubernetes-dashboard&quot; not found
Temporary Error: endpoints &quot;kubernetes-dashboard&quot; not found
</code></pre><p>Solved:<br>Get all of the pods in all namespaces:</p><pre><code>$ kubectl get pods --all-namespaces
NAMESPACE     NAME                          READY     STATUS              RESTARTS   AGE
default       nginx-3449338310-vna7q        0/1       ContainerCreating   0          2h
kube-system   kube-addon-manager-minikube   0/1       ContainerCreating   0          3h
</code></pre><p>Get the description of the pod <code>kube-addon-manager-minikube</code>:</p><pre><code>$ kubectl describe --namespace=kube-system po kube-addon-manager-minikube
Name:		kube-addon-manager-minikube
Namespace:	kube-system
Node:		minikube/192.168.99.100
Start Time:	Mon, 28 Nov 2016 12:17:40 +0800
Labels:		component=kube-addon-manager
		version=v5.1
Status:		Pending
IP:		192.168.99.100
Controllers:	&lt;none&gt;
Containers:
  kube-addon-manager:
    Container ID:	
    Image:		gcr.io/google-containers/kube-addon-manager:v5.1
    Image ID:		
    Port:		
    Requests:
      cpu:			5m
      memory:			50Mi
    State:			Waiting
      Reason:			ContainerCreating
    Ready:			False
    Restart Count:		0
    Environment Variables:	&lt;none&gt;
Conditions:
  Type		Status
  Initialized 	True 
  Ready 	False 
  PodScheduled 	True 
Volumes:
  addons:
    Type:	HostPath (bare host directory volume)
    Path:	/etc/kubernetes/
QoS Tier:	Burstable
No events.
</code></pre><p>Then manually download the docker images of
<code>gcr.io/google-containers/kube-addon-manager:v5.1</code>, load it via following command:</p><pre><code>$ eval $(minikube-linux-amd64 docker-env)
$ docker load&lt;kubeaddonmanagerv51.tar.bz2 
</code></pre><p>Also the default nginx-3449338310-vna7q is failed, use the same method for manually download
the pause image and load it into the docker system:</p><pre><code>$ eval $(minikube-linux-amd64 docker-env)
$ docker load&lt;kubepause30.tar.bz2
</code></pre><p>Also load the dns:</p><pre><code>$ eval $(minikube-linux-amd64 docker-env)
$ docker load&lt;kubedns18.tar.bz2
</code></pre><h3 id=wordpress-installation>Wordpress Installation</h3><p>Refers to :</p><p><a href="https://www.linux-toys.com/?p=887">https://www.linux-toys.com/?p=887</a></p><p>Download yaml file:</p><pre><code>$ wget https://gist.githubusercontent.com/rusher81572/ddf2e1487b609f294b21a2463a8be104/raw/1ba33c7a2dfbef9118c6043030b76babb0a80c7b/wordpress-k8s -O wordpress.yaml
$ sudo docker pull rusher81572/phpfpm
$ sudo docker pull rusher81572/mysql
$ sudo docker pull rusher81572/nginx
</code></pre><p>Create the services from yaml file:</p><pre><code>$ kubectl create -f wordpress.yaml
$ minikube-linux-amd64 service nginx --url
http://192.168.99.100:32400
</code></pre><p>Open the url in your browser:</p><p><img src=/images/2016_11_28_17_24_10_527x489.jpg alt=/images/2016_11_28_17_24_10_527x489.jpg></p><p>Manually create the database named <code>wordpress</code>:</p><pre><code>$ kubectl get pods (To find the Mysql pod name)
$ kubectl exec -it mysql-qe900 bash
$ mysql
$ create database wordpress;
</code></pre><p>Insert the following items in webpage:</p><pre><code>Username: root
Password: sql
Database Name: wordpress
Database Host: mysql
</code></pre><p>After installation, now refresh the webpage you will see the installed wordpress.</p><h3 id=echo-server>Echo Server</h3><p>First download the image and load it into the minikube VM:</p><pre><code>$ docker pull gcr.io/google_containers/echoserver:1.4
$ kubectl run hello-minikube --image=gcr.io/google_containers/echoserver:1.4 \
--hostport=8000 --port=8080 
$ kubectl get pod
NAME                              READY     STATUS    RESTARTS   AGE
hello-minikube-3383150820-x72om   1/1       Running   0          1m
</code></pre><p>You could use <code>kubectl describe pod hellxxxx</code> for displaying the detailed
info.</p><p>Test echo server:</p><pre><code># curl $(minikube service hello-minikube --url) --data &quot;param1=value1&quot;
CLIENT VALUES:
client_address=172.17.0.1
command=POST
real path=/
query=nil
request_version=1.1
request_uri=http://192.168.99.101:8080/

SERVER VALUES:
server_version=nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
accept=*/*
content-length=13
content-type=application/x-www-form-urlencoded
host=192.168.99.101:32520
user-agent=curl/7.51.0
BODY:
param1=value1%                                        
</code></pre><p>Or use nmap for scan all of the ports:</p><pre><code>$ nmap 192.168.99.101

Starting Nmap 7.31 ( https://nmap.org ) at 2016-11-28 22:09 CST
Nmap scan report for 192.168.99.101
Host is up (0.0043s latency).
Not shown: 996 closed ports
PORT      STATE SERVICE
22/tcp    open  ssh
8000/tcp  open  http-alt
8443/tcp  open  https-alt
30000/tcp open  ndmps
</code></pre><p>8000 port is the port listening for, testing this port:</p><pre><code>$  curl http://192.168.99.101:8000 --data &quot;param1=value1&quot;
CLIENT VALUES:
client_address=192.168.99.1
command=POST
real path=/
query=nil
request_version=1.1
request_uri=http://192.168.99.101:8080/

SERVER VALUES:
server_version=nginx: 1.10.0 - lua: 10001

HEADERS RECEIVED:
accept=*/*
content-length=13
content-type=application/x-www-form-urlencoded
host=192.168.99.101:8000
user-agent=curl/7.51.0
BODY:
param1=value1% 
</code></pre><h3 id=deployment-using-dashboard>Deployment Using dashboard</h3><p>Specify the namespace:<br><img src=/images/2016_11_29_10_35_29_283x454.jpg alt=/images/2016_11_29_10_35_29_283x454.jpg></p><p><img src=/images/2016_11_29_10_35_37_205x403.jpg alt=/images/2016_11_29_10_35_37_205x403.jpg></p><p>Create app name:</p><pre><code>App name: hello-yang
Container Image: gcr.io/google_containers/echoserver:1.4
Number of pods: 5
Service: External
Port: 8080  Target port: 8080  Protocol: TCP
</code></pre><p>After deployment, examine the result via:</p><pre><code>➜  ~ kubectl get namespace
NAME            STATUS    AGE
default         Active    14h
devops-meetup   Active    13h
kube-system     Active    14h
➜  ~ kubectl get deployment --namespace=&quot;devops-meetup&quot;
NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
hello-yang   5         5         5            5           24m
</code></pre><p>Delete the deployment via:</p><pre><code># kubectl delete deployment hello-yang --namespace=&quot;devops-meetup&quot;
deployment &quot;hello-yang&quot; deleted
</code></pre><h3 id=deployment-using-yaml>Deployment Using yaml</h3><p>Download the yaml file:</p><pre><code>$  wget
https://raw.githubusercontent.com/kubernetes/kubernetes/master/examples/guestbook/all-in-one/guestbook-all-in-one.yaml
$ vim guestbook-all-in-one.yaml
  # type: LoadBalancer
  type: LoadBalancer
</code></pre><p>Create the service via:</p><pre><code>$ kubectl create -f guestbook-all-in-one.yaml
</code></pre><p>Get the service and view the result:</p><pre><code>➜  ~ kubectl get services
NAME           CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
frontend       10.0.0.164   &lt;pending&gt;     80/TCP     15m
kubernetes     10.0.0.1     &lt;none&gt;        443/TCP    15h
redis-master   10.0.0.100   &lt;none&gt;        6379/TCP   15m
redis-slave    10.0.0.14    &lt;none&gt;        6379/TCP   15m
➜  ~ minikube service frontend --url
http://192.168.99.101:30640
</code></pre><p>Then open the browser and view the result.</p><p><img src=/images/2016_11_29_11_31_56_375x301.jpg alt=/images/2016_11_29_11_31_56_375x301.jpg></p><h3 id=tips>Tips</h3><p>Login to minikube VM:</p><pre><code>$ minikube-linux-amd64 ssh
</code></pre><p>View minikube dashboard URL:</p><pre><code>$ minikube-linux-amd64 dashboard --url
http://192.168.99.100:30000
</code></pre><p>View minikube service URL:</p><pre><code>$ minikube-linux-amd64 service nginx --url
http://192.168.99.100:32400
</code></pre><p>Delete pod in terminating status in force:</p><pre><code># kubectl delete pod mypod --grace-period=0
</code></pre><p>Using kubectl proxy:</p><pre><code>$ kubectl proxy --port=8001
Starting to serve on localhost:8001
</code></pre><p>Now visit: <code>http://localhost:8001/ui</code> for accessing the dashboard.</p><p>wide output:</p><pre><code>$ kubectl get pods -o wide
NAME       READY     STATUS    RESTARTS   AGE       IP           NODE
hugoblog   1/1       Running   2          22h       172.17.0.4   minikube
$ kubectl get pods        
NAME       READY     STATUS    RESTARTS   AGE
hugoblog   1/1       Running   2          22h
</code></pre><p>Create deployment command:</p><pre><code># kubectl run my-nginx --image=nginx --replicas=2 --port=808 --expose
</code></pre><p>so if you want to delete all of the pods, simply delete:</p><pre><code># kubectl delete deployments my-nginx
</code></pre><p>Prevent image pull in json definition files(take zookeeper.json for example):</p><pre><code>$ cat zookeeper.json
{
  &quot;kind&quot;: &quot;Pod&quot;,
  &quot;apiVersion&quot;: &quot;v1&quot;,
  &quot;metadata&quot;: {
    &quot;name&quot;: &quot;zookeeper&quot;,
    &quot;labels&quot;: {
      &quot;name&quot;: &quot;zookeeper&quot;
    }
  },
  &quot;spec&quot;: {
    &quot;containers&quot;: [
      {
        &quot;name&quot;: &quot;zookeeper&quot;,
        &quot;image&quot;: &quot;mattf/zookeeper:latest&quot;,
	&quot;imagePullPolicy&quot;: &quot;IfNotPresent&quot;,
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/11/26/workingtipsonkubernetes/>WorkingTipsOnKubernetes</a></h1><span class=post-date>Nov 26, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=先决条件>先决条件</h3><p>CentOS 7.2 1511, Vagrant for kvm.<br>关闭selinux, 关闭firewalld, 使用以下命令安装docker最新版:</p><pre><code>$ curl -sSL \
http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet |
\ sh -
</code></pre><p>IP地址配置:</p><pre><code>master	192.168.0.223
node1	192.168.0.224
</code></pre><p>配置无密码登录，master到master, master到node1.</p><pre><code># ssh-copy-id root@192.168.0.223
# ssh-copy-id root@192.168.0.224
</code></pre><h3 id=安装kubernetes>安装kubernetes</h3><p>修改配置文件如下:</p><pre><code>$ cat kubernetes/cluster/centos/config-default.sh 

# Master配置
export MASTER=${MASTER:-&quot;root@192.168.0.223&quot;}
export MASTER_IP=${MASTER#*@}

# Minion节点配置
export NODES=${NODES:-&quot;root@192.168.0.223 root@192.168.0.224&quot;}

# Cluster中含有的节点数
export NUM_NODES=${NUM_NODES:-2}

# service cluster配置的IP地址范围
export SERVICE_CLUSTER_IP_RANGE=${SERVICE_CLUSTER_IP_RANGE:-&quot;192.168.22.0/24&quot;}

# flannel的overlay网络IP地址范围, 不能和上面定义的SERVICE_CLUSTER_IP_RANGE地址范围冲突
export FLANNEL_NET=${FLANNEL_NET:-&quot;172.20.0.0/16&quot;}

# Docker参数，这里我们开启daocloud加速模式
export DOCKER_OPTS=${DOCKER_OPTS:-&quot;--cluster-store=etcd://$MASTER_IP:2379, --registry-mirror=http://1a653205.m.daocloud.io&quot;}
</code></pre><p>开始部署kubernetes集群:</p><pre><code>$ KUBERNETES_PROVIDER=centos ./kube-up.sh
</code></pre><p>安装完毕后，运行以下脚本，重新加载docker的配置后，重启两台机器:</p><pre><code>$ sudo systemctl stop docker
$ sudo systemctl daemon-reload
$ sudo systemctl start docker
</code></pre><p>重启完毕后，运行以下命令查看节点状态:</p><pre><code># kubectl get nodes
NAME            STATUS    AGE
192.168.0.223   Ready     10h
192.168.0.224   Ready     10h
</code></pre><p>加载两个docker镜像:</p><pre><code># docker images
gcr.io/google_containers/kubernetes-dashboard-amd64   v1.4.0  
gcr.io/google_containers/pause-amd64                  3.0     
</code></pre><p>添加kubectl到系统路径中:</p><pre><code># cp cluster/centos/binaries/kubectl /opt/kubernetes/bin/
# vim ~/.bashrc
export PATH=$PATH:/opt/kubernetes/bin/
</code></pre><h3 id=启动kubernetes-ui>启动kubernetes UI</h3><p>启动dashboard-controller服务和dashboard-service服务:</p><pre><code># cd ./cluster/gce/coreos/kube-manifests/addons/dashboard
# kubectl create -f dashboard-controller.yaml 
# kubectl create -f dashboard-service.yaml 
</code></pre><p>在node1上可以查看docker运行状态:</p><pre><code># docker ps
b22047f30d55        gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.0   &quot;/dashboard --port=90&quot;
8979b7b1db14        gcr.io/google_containers/pause-amd64:3.0                     &quot;/pause&quot;
</code></pre><p>查看<code>http://192.168.0.223:8080/ui</code>，得到dashboard的网页.</p><p><img src=/images/2016_11_26_22_01_29_891x497.jpg alt=/images/2016_11_26_22_01_29_891x497.jpg></p><p>service截图:</p><p><img src=/images/2016_11_26_22_03_57_758x176.jpg alt=/images/2016_11_26_22_03_57_758x176.jpg></p><h3 id=nginx服务>nginx服务</h3><p>配置nginx-rc.yaml文件用于启动nginx服务:</p><pre><code>$ vim nginx-rc.yaml 
apiVersion: v1 
kind: ReplicationController 
metadata: 
  name: nginx-controller 
spec: 
  replicas: 2 
  selector: 
    name: nginx 
  template: 
    metadata: 
      labels: 
        name: nginx 
    spec: 
      containers: 
        - name: nginx
          image: nginx
          ports: 
            - containerPort: 80
</code></pre><p>启动服务:</p><pre><code>$ kubectl -s http://192.168.0.223:8080 create -f nginx-rc.yaml
</code></pre><p>检查创建的pods情况:</p><pre><code># kubectl get pods
NAME                     READY     STATUS              RESTARTS   AGE
nginx-controller-1bx6j   0/1       ContainerCreating   0          13s
nginx-controller-attgh   0/1       ContainerCreating   0          13s
</code></pre><p>得到pod的运行情况:</p><pre><code># kubectl describe pod nginx-controller-1bx6j
Name:		nginx-controller-1bx6j
Namespace:	default
Node:		192.168.0.224/192.168.0.224
Start Time:	Sat, 26 Nov 2016 14:08:33 +0000
Labels:		name=nginx
Status:		Running
IP:		172.20.99.3
Controllers:	ReplicationController/nginx-controller
......
</code></pre><p>此刻可以在对应的节点上看到nginx的运行情况: <code>curl 172.20.99.3</code>在master节点上。</p><h3 id=节点内可访问的nginx-service>节点内可访问的nginx service</h3><p>Service的type有ClusterIP和NodePort之分，缺省是ClusterIP，这种类型的Service
只能在集群内部访问。配置文件如下：</p><pre><code>$ vim nginx-service-clusterip.yaml 
apiVersion: v1 
kind: Service 
metadata: 
  name: nginx-service-clusterip 
spec: 
  ports: 
    - port: 8001 
      targetPort: 80 
      protocol: TCP 
  selector: 
    name: nginx
</code></pre><p>创建服务:</p><pre><code># kubectl create -f nginx-service-clusterip.yaml
</code></pre><p>查看创建出的service情况:</p><pre><code># kubectl get service
NAME                      CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
kubernetes                192.168.22.1     &lt;none&gt;        443/TCP    34m
nginx-service-clusterip   192.168.22.189   &lt;none&gt;        8001/TCP   27s
</code></pre><p>访问节点内可访问的nginx service, 在master和node1上都可以访问到:</p><pre><code>$ curl 192.168.22.189:8001
</code></pre><h3 id=外部可访问的nginx服务>外部可访问的nginx服务</h3><p>type为NodePort的为外部可访问的nginx服务，定义文件如下:</p><pre><code>$ vim nginx-service-nodeport.yaml 
apiVersion: v1 
kind: Service 
metadata: 
  name: nginx-service-nodeport 
spec: 
  ports: 
    - port: 8000
      targetPort: 80 
      protocol: TCP 
  type: NodePort
  selector: 
    name: nginx
</code></pre><p>运行<code>kubectl create -f nginx-service-nodeport.yaml</code>, 得到服务如下:</p><pre><code># kubectl get service
NAME                      CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
kubernetes                192.168.22.1     &lt;none&gt;        443/TCP    58m
nginx-service-clusterip   192.168.22.189   &lt;none&gt;        8001/TCP   23m
nginx-service-nodeport    192.168.22.209   &lt;nodes&gt;       8000/TCP   2m
</code></pre><p>可以看到，新增加了一个<code>nginx-service-nodeport</code>的服务.</p><p>查看其端口，30923为其映射的端口号:</p><pre><code># kubectl describe service nginx-service-nodeport
Name:			nginx-service-nodeport
Namespace:		default
Labels:			&lt;none&gt;
Selector:		name=nginx
Type:			NodePort
IP:			192.168.22.209
Port:			&lt;unset&gt;	8000/TCP
NodePort:		&lt;unset&gt;	30923/TCP
Endpoints:		172.20.62.2:80,172.20.99.3:80
Session Affinity:	None
</code></pre><p>从外部(192.168.0.220)验证nginx服务:</p><pre><code># curl http://192.168.0.223:30923
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</code></pre><h3 id=删除服务>删除服务</h3><p>删除我们上面创建的基于nodeport的服务:</p><pre><code># kubectl delete -f ./nginx-service-nodeport.yaml
</code></pre><p>删除以后，检查service情况:</p><pre><code># kubectl get service
NAME                      CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
kubernetes                192.168.22.1     &lt;none&gt;        443/TCP    1h
nginx-service-clusterip   192.168.22.189   &lt;none&gt;        8001/TCP   55m
</code></pre><p>可以看到<code>nginx-service-nodeport</code>服务已经被删除。</p><h3 id=指定端口>指定端口</h3><p>创建配置文件如下:</p><pre><code>$ vim specifynode.yaml 
apiVersion: v1 
kind: Service 
metadata: 
  name: nginx-service-nodeport 
spec: 
  ports: 
    - port: 80
      nodePort: 30080 
      protocol: TCP 
  type: NodePort
  selector: 
    name: nginx
</code></pre><p>创建服务:</p><pre><code>$ kubectl create -f ./specifynode.yaml
</code></pre><p>现在访问<code>http://192.168.0.223:30080</code>即可访问到nginx服务.</p><p>注: 端口需要绑定在<code>30000-32767</code>.</p></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/105/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/105/>105</a></li><li class="page-item active"><a class=page-link href=/page/106/>106</a></li><li class=page-item><a class=page-link href=/page/107/>107</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/240/>240</a></li><li class=page-item><a href=/page/107/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/240/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>