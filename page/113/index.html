<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/12/21/trycoreos3/>TryCoreOS(3)</a></h1><span class=post-date>Dec 21, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=fleetctl-configuration>fleetctl Configuration</h3><h4 id=cluster-status>Cluster Status</h4><p><code>fleetctl list-machines</code> will display all of the nodes in cluster:</p><pre><code>core@coreos1 ~ $ fleetctl list-machines
MACHINE		IP		METADATA
bea5741d...	172.17.8.203	-
dd464e69...	172.17.8.202	-
f22aee5d...	172.17.8.201	-
</code></pre><p><code>fleetctl list-units</code> will list all of the services in cluster:</p><pre><code>core@coreos1 ~ $ fleetctl list-units
UNIT	MACHINE	ACTIVE	SUB
</code></pre><h4 id=nodes-jumping>Nodes Jumping</h4><p>Use <code>ssh-keygen</code> for generating the <code>id_rsa.pub</code>, and add them into other
nodes&rsquo;s <code>/home/core/.ssh/authorized_keys</code>.</p><p>Start the ssh-agent via:</p><pre><code>$ eval `ssh-agent`
$ ssh-add /home/core/.ssh/id_rsa
$ fleetctl ssh dd464e69
</code></pre><p>List the added ssh key via:</p><pre><code>$ ssh-add  -l
2048 SHA256:w7OM8b6ximc9/lTgaB5gWpHK6xuf22IE37Of113yfJA /home/core/.ssh/id_rsa (RSA)
</code></pre><p>Then you could use <code>fleetctl ssh dd464e69</code> for jumping to <code>172.17.8.202</code>.</p><p>Or execute command like following:</p><pre><code> $ fleetctl ssh dd464e69 cat /etc/hostname
coreos2
</code></pre><h3 id=start-first-fleet-unit>Start First Fleet Unit</h3><p>In core1 node, do following operation:</p><pre><code>$ cp /etc/systemd/system/hello.service ./
$ vim hello.service 
$ fleetctl start ./hello.service 
</code></pre><p>Your hello.service should be like this:</p><pre><code>[Unit] 
Description=Hello World 
After=docker.service 
Requires=docker.service 

[Service] 
TimeoutStartSec=0 
ExecStartPre=-/bin/docker kill busybox1 
ExecStartPre=-/bin/docker rm busybox1 
ExecStart=/bin/docker run --name busybox1 busybox /bin/sh -c &quot;while true; do
echo Hello World; sleep 1; done&quot; 
ExecStop=&quot;/bin/docker kill busybox1&quot;

[X-Fleet]
X-Conflicts=hello*.service
</code></pre><p>Mainly the same as systemd&rsquo;s configuration, but replace the last part to
<code>X-Fleet</code>.</p><p>Start the unit via:</p><pre><code>core@coreos1 ~ $ fleetctl start ./hello.service 
Unit hello.service inactive
Unit hello.service launched on bea5741d.../172.17.8.203
core@coreos1 ~ $ fleetctl list-units
UNIT		MACHINE				ACTIVE	SUB
hello.service	bea5741d.../172.17.8.203	active	running
</code></pre><p>In node3(172.17.8.203), you could use <code>systemctl list-units</code> for finding the
service named <code>hello.service</code>.</p><h3 id=service-migration>Service Migration</h3><p>Step1: Login to hello.service machine.<br>Step2: Reboot this node.<br>Step3: View current units has been migrated to new node.<br>Step4: List the avaiable machines.</p><pre><code>core@coreos1 ~ $ fleetctl ssh hello.service
Last login: Wed Dec 21 10:24:15 UTC 2016 from 172.17.8.201 on pts/1
CoreOS stable (1185.5.0)
core@coreos3 ~ $ systemctl reboot
core@coreos3 ~ $ core@coreos1 ~ $ 
core@coreos1 ~ $ fleetctl list-units
UNIT		MACHINE				ACTIVE	SUB
hello.service	dd464e69.../172.17.8.202	active	running
core@coreos1 ~ $ fleetctl list-machines
MACHINE		IP		METADATA
dd464e69...	172.17.8.202	-
f22aee5d...	172.17.8.201	-
</code></pre><h3 id=destroy-service>Destroy Service</h3><p>If you want to destroy the service, do following:</p><pre><code>core@coreos1 ~ $ fleetctl list-unit-files
UNIT		HASH	DSTATE		STATE		TARGET
hello.service	09bb151	launched	launched
dd464e69.../172.17.8.202
core@coreos1 ~ $ fleetctl destroy hello.service
Destroyed hello.service
core@coreos1 ~ $ fleetctl list-unit-files
UNIT	HASH	DSTATE	STATE	TARGET
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/12/21/trycoreos2/>TryCoreOS(2)</a></h1><span class=post-date>Dec 21, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=local-discovery-service>Local Discovery Service</h3><p>Take a look at the yaml configuration file:</p><pre><code>  etcd2:
    # generate a new token for each unique cluster from
https://discovery.etcd.io/new?size=3
    # specify the initial size of your cluster with ?size=X
    discovery: https://discovery.etcd.io/4add2186302763c8876afd1684ca06fe
</code></pre><p>This means all of you coreos nodes should reach the internet, what if we
deploy a coreos cluster offline? We need to deploy a local discovery service.</p><h4 id=archlinux-etcd2-example>ArchLinux etcd2 Example</h4><p>Download the etcd v2.3.7 and extract it to specified directory via :</p><pre><code>$ curl -L \
https://github.com/coreos/etcd/releases/download/v2.3.7/etcd-v2.3.7-linux-amd64.tar.gz \
-o etcd-v2.3.7-linux-amd64.tar.gz
$ tar xzvf etcd-v2.3.7-linux-amd64.tar.gz
</code></pre><p>Create a customized systemd item like following, you should change the etcd
executable file to your own positioni, also specify your own <code>data-dir</code>:</p><pre><code>$ sudo mkdir -p /var1/Nov14/etcd/etcd-v2.3.7-linux-amd64/data
$ sudo vim /usr/lib/systemd/system/myetcd.service 
[Unit]
Description=myownetcd
After=multi-user.service

[Service]
ExecStart=/var1/Nov14/etcd/etcd-v2.3.7-linux-amd64/etcd
--data-dir=/var1/Nov14/etcd/etcd-v2.3.7-linux-amd64/data
--name=single-etcd-service  --listen-client-urls
'http://0.0.0.0:2379,http://0.0.0.0:4001' --advertise-client-urls
'http://0.0.0.0:2379,http://0.0.0.0:4001'
Restart=always
StandardOutput=syslog
StandardError=syslog
SyslogIdentifier=myownetcd

[Install]
WantedBy=multi-user.target
</code></pre><p>Start and enable the service:</p><pre><code>$ sudo systemctl enable myetcd.service
$ sudo systemctl start myetcd.service
</code></pre><h4 id=test-etcd>Test etcd</h4><p>Very simple test:</p><pre><code>$ ./etcdctl set mykey &quot;this is awesome&quot;
$ ./etcdctl get mykey
this is awesome
</code></pre><h4 id=create-own-discovery>Create own discovery</h4><p>Use <code>uuidgen</code> for generating a new uuid:</p><pre><code>$ uuidgen 
557a2133-88f3-41d2-9b27-9fd4081f7b41
</code></pre><p>Use this new generated uuid for generating a 3-node cluster:</p><pre><code>$ curl -X PUT \
http://172.17.8.1:4001/v2/keys/557a2133-88f3-41d2-9b27-9fd4081f7b41/_config/size \
-d value=3
</code></pre><p>Now you could examine the generated etcd items:</p><pre><code>$ /var1/Nov14/etcd/etcd-v2.3.7-linux-amd64/etcdctl ls --recursive /
/mykey
/557a2133-88f3-41d2-9b27-9fd4081f7b41
</code></pre><h4 id=use-your-own-discovery>Use your own discovery</h4><p>Change the definition in yaml file:</p><pre><code>    #discovery: https://discovery.etcd.io/4add2186302763c8876afd1684ca06fe
    discovery: http://172.17.8.1:4001/v2/keys/557a2133-88f3-41d2-9b27-9fd4081f7b41
</code></pre><p>Now re-create the coreOS cluster, you will see the coreOS cluster could
work properly again.</p><h3 id=start-first-docker>Start First Docker</h3><p>Enable registry-mirror in coreOS:</p><pre><code># echo 'DOCKER_OPTS=&quot;--registry-mirror=http://1a653205.m.daocloud.io&quot;' &gt;&gt; /run/flannel_docker_opts.env
# systemctl restart docker
# docker pull busybox
</code></pre><p>Now write the hello.service definition:</p><pre><code># vim /etc/systemd/system/hello.service
[Unit] 
Description=Hello World 
After=docker.service 
Requires=docker.service 

[Service] 
TimeoutStartSec=0 
ExecStartPre=-/bin/docker kill busybox1 
ExecStartPre=-/bin/docker rm busybox1 
ExecStart=/bin/docker run --name busybox1 busybox /bin/sh -c &quot;while true; do echo Hello World; sleep 1; done&quot; 
ExecStop=&quot;/bin/docker kill busybox1&quot;
ExecStopPost=&quot;/bin/docker rm busybox1&quot;
 
[Install] 
WantedBy=multi-user.target
</code></pre><p>Start and enable the service via:</p><pre><code># systemctl start hello.service
# systemctl enable hello.service
</code></pre><h3 id=trouble-shooting>Trouble-Shooting</h3><p>Reset your etcd2 database:</p><pre><code>$ sudo systemctl stop fleetd
$ sudo systemctl stop etcd2
$ sudo rm -rf /var/lib/etcd2/*
$ sudo rm -rf /etc/systemd/system/etcd* 
$ sudo reboot 
</code></pre><p>Then your etcd2 will be re-initialized.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/12/20/trycoreos/>TryCoreOS</a></h1><span class=post-date>Dec 20, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=preparation>Preparation</h3><p>Create image file via:</p><pre><code>$ sudo mkdir corecluster
$ cd corecluster
$ qemu-img create -f qcow2 coreos1.qcow2 30G
$ qemu-img create -f qcow2 coreos2.qcow2 30G
$ qemu-img create -f qcow2 coreos3.qcow2 30G
</code></pre><p>Create a network named <code>172.17.8.1/24</code>, dhcp disabled.</p><p>Since the vnet interface is occupied via virtualbox, switches to virtualbox
installation.</p><p>Two Ethernet cards:</p><p><img src=/images/2016_12_20_17_36_44_697x413.jpg alt=/images/2016_12_20_17_36_44_697x413.jpg></p><p>Start from CD:</p><p><img src=/images/2016_12_20_17_37_26_678x304.jpg alt=/images/2016_12_20_17_37_26_678x304.jpg></p><h3 id=installation-file-preparation>Installation File Preparation</h3><p>For saving time, we use local installation repository, download the
installation images via:</p><pre><code>$ $ git clone https://github.com/coreos/coreos-baremetal
# Make a copy of example files
$ cp -R coreos-baremetal/examples .
# Download the CoreOS image assets referenced in the target profile.
$ ./coreos-baremetal/scripts/get-coreos stable 1185.5.0 ./examples/assets
</code></pre><p>Then Copy installation image and sig file into the webserver:</p><pre><code>$ cd /YourWebServerDirectory/1185.5.0 
$ ls
coreos_production_image.bin.bz2  coreos_production_image.bin.bz2.sig
</code></pre><h3 id=yaml-definition>YAML Definition</h3><p>Refers to <code>coreos-vagrant</code> project:</p><pre><code>$ git clone https://github.com/coreos/coreos-vagrant.git`
$ cat user-data
</code></pre><p>The configuration of the yaml is listed as following:</p><p>First get the token via:</p><pre><code>$ curl https://discovery.etcd.io/new?size=3
https://discovery.etcd.io/xxxxxxxxxxxxxxxxxxxxxxxxx
</code></pre><pre><code>#cloud-config
hostname: coreos1 
coreos:
  etcd2:
    # generate a new token for each unique cluster from https://discovery.etcd.io/new?size=3
    # specify the initial size of your cluster with ?size=X
    discovery: https://discovery.etcd.io/xxxxxxxxxxxxxxxxxxx
    advertise-client-urls: http://172.17.8.201:2379,http://172.17.8.201:4001
    initial-advertise-peer-urls: http://172.17.8.201:2380
    # listen on both the official ports and the legacy ports
    # legacy ports can be omitted if your application doesn't depend on them
    listen-client-urls: http://0.0.0.0:2379,http://0.0.0.0:4001
    listen-peer-urls: http://172.17.8.201:2380,http://172.17.8.201:7001
  fleet:
    public-ip: &quot;172.17.8.201&quot;
  flannel:
    interface: &quot;172.17.8.201&quot;
  units:
    - name: etcd2.service
      command: start
    - name: fleet.service
      command: start
    - name: flanneld.service
      drop-ins:
      - name: 50-network-config.conf
        content: |
          [Service]
          ExecStartPre=/usr/bin/etcdctl set /coreos.com/network/config '{ &quot;Network&quot;: &quot;10.1.0.0/16&quot; }'
      command: start
    - name: static.network
      content: |
        [Match]
        Name=enp0s8
        [Network]
        Address=172.17.8.201/24
        Gateway=172.17.8.1
        DNS=172.17.8.1
    - name: docker-tcp.socket
      command: start
      enable: true
      content: |
        [Unit]
        Description=Docker Socket for the API
  
        [Socket]
        ListenStream=2375
        Service=docker.service
        BindIPv6Only=both
  
        [Install]
        WantedBy=sockets.target
users:  
  - name: core
    ssh-authorized-keys: 
      - ssh-rsa &quot;ADD ME&quot;
  - groups:
      - sudo
      - docker
</code></pre><p>For coreos2 node, simply replace the ip address from <code>172.17.8.201</code> to <code>172.17.8.202</code>, etc.</p><h3 id=installation>Installation</h3><p>Install it via:</p><pre><code># coreos-install -d /dev/sda -b http://YourWebServer -c ./YourYamlFile.yaml -v
</code></pre><p>After a while, the installation will finish.</p><p>Repeat this step in 3 nodes.</p><h3 id=verification>Verification</h3><p>Login into any of the core machine in cluster:</p><pre><code>core@coreos1 ~ $ etcdctl cluster-health
member f934a5ba1eca1ea is healthy: got healthy result from http://172.17.8.201:2379
member 23798f79754d53b7 is healthy: got healthy result from http://172.17.8.203:2379
member 5acdd34e67ade1d7 is healthy: got healthy result from http://172.17.8.202:2379
cluster is healthy
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/12/15/usemesosforci/>UseMesosForCI</a></h1><span class=post-date>Dec 15, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>参考了<a href=http://container-solutions.com/continuous-delivery-with-docker-on-mesos-in-less-than-a-minute/>http://container-solutions.com/continuous-delivery-with-docker-on-mesos-in-less-than-a-minute/</a></p><h3 id=nodejs程序>Nodejs程序</h3><p>app.js程序如下:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-javascript data-lang=javascript><span style=color:#75715e>// Load the http module to create an http server.
</span><span style=color:#75715e></span><span style=color:#66d9ef>var</span> <span style=color:#a6e22e>http</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>require</span>(<span style=color:#e6db74>&#39;http&#39;</span>);
 
<span style=color:#75715e>// Configure our HTTP server to respond with Hello World to all requests.
</span><span style=color:#75715e></span><span style=color:#66d9ef>var</span> <span style=color:#a6e22e>server</span> <span style=color:#f92672>=</span> <span style=color:#a6e22e>http</span>.<span style=color:#a6e22e>createServer</span>(<span style=color:#66d9ef>function</span> (<span style=color:#a6e22e>request</span>, <span style=color:#a6e22e>response</span>) {
  <span style=color:#a6e22e>response</span>.<span style=color:#a6e22e>writeHead</span>(<span style=color:#ae81ff>200</span>, {<span style=color:#e6db74>&#34;Content-Type&#34;</span><span style=color:#f92672>:</span> <span style=color:#e6db74>&#34;text/plain&#34;</span>});
  <span style=color:#a6e22e>response</span>.<span style=color:#a6e22e>end</span>(<span style=color:#e6db74>&#34;Hello World&#34;</span>);
});
 
<span style=color:#75715e>// Listen on port 8000, IP defaults to &#34;0.0.0.0&#34;
</span><span style=color:#75715e></span><span style=color:#a6e22e>server</span>.<span style=color:#a6e22e>listen</span>(<span style=color:#ae81ff>8000</span>);
 
<span style=color:#75715e>// Put a friendly message on the terminal
</span><span style=color:#75715e></span><span style=color:#a6e22e>console</span>.<span style=color:#a6e22e>log</span>(<span style=color:#e6db74>&#34;Server running at http://127.0.0.1:8000/&#34;</span>);
</code></pre></div><p>配置文件package.json如下:</p><pre><code>{
  &quot;name&quot;: &quot;hello-world&quot;,
  &quot;description&quot;: &quot;hello world&quot;,
  &quot;version&quot;: &quot;0.0.1&quot;,
  &quot;private&quot;: true,
  &quot;dependencies&quot;: {
    &quot;express&quot;: &quot;3.x&quot;
  },
  &quot;scripts&quot;: {&quot;start&quot;: &quot;node app.js&quot;}
}
</code></pre><p>创建容器的Dockerfile定义如下:</p><pre><code>FROM google/nodejs
 
WORKDIR /app
ADD package.json /app/
RUN npm install
ADD . /app
 
EXPOSE 8000
CMD []
ENTRYPOINT [&quot;/nodejs/bin/npm&quot;, &quot;start&quot;]
</code></pre><p>于是我们可以编译出自定义的容器镜像:</p><pre><code>$ docker build -t my_nodejs_image .
$ docker run -p 8000:8000 my_nodejs_image
</code></pre><p>这时候访问<code>http://localhost:8000</code>即可看到APP有<code>hello world</code>的输出。</p><h3 id=引入jenkins>引入Jenkins</h3><p>获取docker的group id:</p><pre><code># cat /etc/group | grep -i docker
docker:x:998:vagrant
</code></pre><p>定义Dockerfile， 注意我们这里有998的替代:</p><pre><code>FROM jenkins

MAINTAINER ContainerSolutions

USER root
#TODO the group ID for docker group on my Ubuntu is 125, therefore I can only
# run docker commands if I have same group id inside. 
# Otherwise the socket file is not accessible.
RUN groupadd -g 998 docker; usermod -a -G docker jenkins 
USER jenkins
</code></pre><p>编译docke镜像:</p><pre><code># docker build -t dash/jenkins_with_docker .
# docker images | grep dash
dash/jenkins_with_docker                 latest              6dc4c6263f78
25 seconds ago      712 MB
</code></pre><p>创建docker-compose.yml文件:</p><pre><code>jenkins:
  image: dash/jenkins_with_docker
  volumes:
    - jenkins-stuff:/var/jenkins_home
    - .:/var/jenkins_data
    - /var/run/docker.sock:/var/run/docker.sock
    - /usr/bin/docker:/usr/bin/docker
  ports: 
    - &quot;8081:8080&quot;
registry:
  image: registry
  environment:
    - STORAGE_PATH=/registry
  volumes:
    - registry-stuff:/registry
  ports: 
    - &quot;5000:5000&quot;
</code></pre><p>现在运行<code>docker-compose up</code>，并检查服务状态,
如果之前已经运行过，则需要删除以前的卷，<code>docker volume rm jenkins-stuff</code></p><pre><code>root@ci:~# netstat -anp | grep 5000
tcp6       0      0 :::5000                 :::*                    LISTEN
1983/docker-proxy
root@ci:~# netstat -anp | grep 8081
tcp6       0      0 :::8081                 :::*                    LISTEN
1917/docker-proxy
</code></pre><p>可以通过访问<code>http://localhost:8081</code>来查看jenkins界面。</p><p><img src=/images/2016_12_15_21_54_18_773x321.jpg alt=/images/2016_12_15_21_54_18_773x321.jpg></p><p>获取密码的步骤如下:</p><pre><code># docker ps | grep -i dash
CONTAINER ID        IMAGE                      COMMAND
CREATED              STATUS              PORTS
NAMES
dashcompose_registry_1
74aeca2d56c5        dash/jenkins_with_docker   &quot;/bin/tini -- /usr/lo&quot;   About
a minute ago   Up About a minute   50000/tcp, 0.0.0.0:8081-&gt;8080/tcp
dashcompose_jenkins_1
# docker exec -it 74aeca2d56c5 /bin/bash
jenkins@74aeca2d56c5:/$ cat /var/jenkins_home/secrets/initialAdminPassword
e8902ae0e7d84cc6848fb79cf7e64538
</code></pre><p>选择不添加任何插件，直接进入到jenkins.</p><p><img src=/images/2016_12_15_21_58_16_669x452.jpg alt=/images/2016_12_15_21_58_16_669x452.jpg></p><p>查看已经添加的卷的详细信息:</p><pre><code># docker volume ls
DRIVER              VOLUME NAME
local
049c2b4d14069f74ded6ed1286694a7a43b391aac5345f63fdb23b6c0a453d32
local
8ad894e25c1fd64b229bd4cb777ea37895b15acfeeee9e4de1cb07ef7e1e1649
local
9033c8aa23972d703e54aed1647516577866aff738929f09e4070106b24a5edf
local
f8c0327e154ceb284e9444fba4dfa53b7d92651c9fce44611d98873adb1e5051
local               jenkins-stuff
local               registry-stuff
# docker volume inspect jenkins-stuff
[
    {
        &quot;Name&quot;: &quot;jenkins-stuff&quot;,
        &quot;Driver&quot;: &quot;local&quot;,
        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/jenkins-stuff/_data&quot;,
        &quot;Labels&quot;: null,
        &quot;Scope&quot;: &quot;local&quot;
    }
]
</code></pre><p>可以看到我们添加的卷挂载的目录， 那么建立以下的目录:</p><pre><code>$ sudo mkdir /var/lib/docker/volumes/jenkins-stuff/_data/workspace/dockerbuild
</code></pre><p>创建两个脚本，一个用来编译，一个用来推送已经编译好的docker镜像:</p><pre><code># cat build.sh 
#!/bin/bash
 
if [ -z &quot;${1}&quot; ]; then
   version=&quot;latest&quot;
else
   version=&quot;${1}&quot;
fi
 
cd nodejs_app
docker build -t localhost:5000/containersol/nodejs_app:${version} .
cd ..
# cat push.sh 
#!/bin/bash

if [ -z &quot;${1}&quot; ]; then
   version=&quot;latest&quot;
else
   version=&quot;${1}&quot;
fi

docker push localhost:5000/containersol/nodejs_app:&quot;${version}&quot;
</code></pre><p>同样将我们的app拷贝到这个目录下，目录树如下：</p><pre><code># tree
.
├── build.sh
├── nodejs_app
│   ├── app.js
│   ├── Dockerfile
│   └── package.json
└── push.sh

1 directory, 5 files
</code></pre><p>Jenkins里新建的project中，build选项如下:</p><p><img src=/images/2016_12_16_09_39_40_888x659.jpg alt=/images/2016_12_16_09_39_40_888x659.jpg></p><p>现在触发编译，直接点击<code>build now</code>，则可以看到每一次执行的build中的console out.</p><p><img src=/images/2016_12_16_09_41_09_343x258.jpg alt=/images/2016_12_16_09_41_09_343x258.jpg></p><p>编译完毕后，可以看到docker镜像库中新添加的镜像:</p><pre><code># docker images
REPOSITORY                               TAG                 IMAGE ID            CREATED             SIZE
localhost:5000/containersol/nodejs_app   10                  18462939f95d        11 minutes ago      502 MB
localhost:5000/containersol/nodejs_app   11                  18462939f95d        11 minutes ago      502 MB
localhost:5000/containersol/nodejs_app   9                   c163d485bce3        13 minutes ago      502 MB
</code></pre><p>验证方法则是手动执行该镜像的实例，例如我们修改app.js:</p><pre><code># vim app.js 
// Load the http module to create an http server.
var http = require('http');
 
// Configure our HTTP server to respond with Hello World to all requests.
var server = http.createServer(function (request, response) {
  response.writeHead(200, {&quot;Content-Type&quot;: &quot;text/plain&quot;});
  response.end(&quot;Hello World , build me now!&quot;);
});
</code></pre><p>触发build并验证后，可以看到输出为:</p><pre><code># curl http://127.0.0.1:8000
Hello World , build me now!
</code></pre><h3 id=tbd>TBD</h3><p>可以映射jenkins默认编译目录为某个本地目录，或者在Jenkins容器配置文件中
指定好其编译目录。</p><p>可以将jenkins与git结合。</p><p>如果需要用mesos来自动deploy app，可以参考:</p><p><a href=http://container-solutions.com/continuous-delivery-with-docker-on-mesos-in-less-than-a-minute-part-2/>http://container-solutions.com/continuous-delivery-with-docker-on-mesos-in-less-than-a-minute-part-2/</a></p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/blog/2016/12/11/offlineinstalljavaonubuntu1404/>OfflineInstallJavaOnUbuntu1404</a></h1><span class=post-date>Dec 11, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>在ubuntu14.04上搭建mesos时，需要安装jdk8或jdk9，然而官方仓库中没有类似的选项，
因而有两种work-around，第一种是手动安装jdk， 第二种是使用第三方库安装.</p><h3 id=手动安装>手动安装</h3><p>下载安装包:</p><pre><code>$ wget --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot;
http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jdk-8u111-linux-x64.tar.gz
</code></pre><p>如果是jdk9，则下载安装包为:</p><pre><code>$ wget
http://www.java.net/download/java/jdk9/archive/140/binaries/jdk-9-ea+140_linux-x64_bin.tar.gz
</code></pre><p>下载完毕后，安装步骤如下:</p><pre><code>$ sudo bash
# tar -zxf jdk-9-ea+140_linux-x64_bin.tar.gz -C /opt/jdk/
# update-alternatives --install /usr/bin/java java /opt/jdk/jdk-9/bin/java 100
# update-alternatives --install /usr/bin/javac javac /opt/jdk/jdk-9/bin/javac 100
# update-alternatives --display java
# update-alternatives --display javac
</code></pre><h3 id=第三方库>第三方库</h3><p>激活ppa库如下:</p><pre><code>$ sudo add-apt-repository ppa:webupd8team/java
$ sudo apt-get update
$ sudo apt-get install oracle-java8-installer
$ sudo apt-get install oracle-java8-set-default
</code></pre><p>在安装过程中需要从oracle官方网站下载安装包，为了避免重复下载过程，可以将安装包直接拷贝到
<code>/var/cache/oracle-jdk9-installer</code>目录或者<code>/var/cache/oracle-jdk8-installer</code>目录。</p></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/112/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/112/>112</a></li><li class="page-item active"><a class=page-link href=/page/113/>113</a></li><li class=page-item><a class=page-link href=/page/114/>114</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/249/>249</a></li><li class=page-item><a href=/page/114/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/249/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>