<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/27/shi-yong-fuelbu-shu-opencontrail-5/>使用Fuel部署OpenContrail(5)</a></h1><span class=post-date>Apr 27, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>本节主要用于配置OpenStack使用OpenContrail作为其网络配置器，主要涉及到OpenStack Controller和OpenStack Compute上的配置.</p><h3 id=openstack-controller配置>OpenStack Controller配置</h3><p>!!! 以下的所有操作，需要在每个OpenStack Controller节点上进行！！！
OpenStack Controller不需要使用Private 网络，所以我们可以删除ifcfg-eth0文件:</p><pre><code># rm -f /etc/network/interface.d/ifcfg-eth4
# service networking restart

</code></pre><p>为了保险，最好重启更改完网络后的节点。<br>配置/etc/nova/nova.conf文件中的以下字段:</p><pre><code># vim /etc/nova/nova.conf
[DEFAULT]
network_api_class = nova.network.neutronv2.api.API
neutron_url = http://10.77.77.9:9696
neutron_admin_tenant_name = services
neutron_admin_username = neutron
neutron_admin_password = rVlaAKUs
neutron_url_timeout = 300
neutron_admin_auth_url = http://10.55.55.4:35357/v2.0/
firewall_driver = nova.virt.firewall.NoopFirewallDriver
enabled_apis = ec2,osapi_compute,metadata
security_group_api = neutron
service_neutron_metadata_proxy = True

</code></pre><p>neutron_admin_password的值还是我们以前取得的admin token.<br>更改完上述配置后，重启以下服务:</p><pre><code># service nova-api restart
# service nova-scheduler restart
# service nova-conductor restart

</code></pre><p>在任一OpenStack Controller节点上，使用以下命令，在数据库中删除nova-network服务的定义。</p><pre><code># source ~/openrc
# for i in $(nova service-list|grep nova-network|awk '{print $2}'); \
do nova service-delete $i;done

</code></pre><h3 id=compute计算节点配置>Compute(计算)节点配置</h3><p>!!! 以下操作，都应该在每个计算节点上运行 !!!!
在每个计算节点上，配置仓库:</p><pre><code>#  echo 'deb http://10.20.0.2:8080/contrail/ /' &gt;/etc/apt/sources.list.d/contrail.list
# echo -e &quot;Package: *\nPin: release l=Ubuntu\nPin-Priority: 100&quot; &gt; /etc/apt/preferences
# &gt;/etc/apt/sources.list
# apt-get update

</code></pre><p>Contrail是不需要OpenVSwitch(OVS)的，所以我们要把它删除:</p><pre><code># apt-get purge -y openvswitch-common openvswitch-datapath-lts-saucy-dkms \
openvswitch-switch nova-network nova-api

</code></pre><p>验证openvswitch是否被彻底删除(应该输出空行才对):</p><pre><code># aptitude search -F '%p' '~i' | grep openvswitch

</code></pre><p>删除OVS的内核模块:</p><pre><code># lsmod | grep openvswitch &amp;&amp; rmmod openvswitch

</code></pre><p>移除virbr0端口:</p><pre><code># virsh net-destroy default
# virsh net-undefine default

</code></pre><p>确保在所有节点的/etc/network/interface.d/下，只包括了ifcfg-eth0, ifcfg-eth4, 其他都需要被删除。<br>重启所有OpenStack Compute节点，以删除所有openvswitch和nova-network相关的iptables规则、接口等。</p><pre><code># reboot 

</code></pre><p>重启以后，以下面的命令确保没有NAT规则存在:</p><pre><code># iptables -L -t nat

</code></pre><p>在所有的Compute节点上，安装Contrail vrouter 组件:</p><pre><code># apt-get install -y contrail-openstack-vrouter

</code></pre><p>所有节点上，配置vhost0和ifcfg-eth4:</p><pre><code>root@node-18:~# vim /etc/network/interfaces.d/ifcfg-vhost0 
auto vhost0
iface vhost0 inet static
    netmask 255.255.255.0
    network_name application
    address 10.77.77.15
    gateway 10.77.77.1
    mtu 1300
root@node-18:~# vim /etc/network/interfaces.d/ifcfg-eth4 
auto eth4
iface eth4 inet manual

up ip l set eth4 up
down ip l set eth4 down

post-up  ethtool  -K  eth4  gso off  gro off || true

</code></pre><p>创建agent_param文件:</p><pre><code># mv /etc/contrail/agent_param.tmpl /etc/contrail/agent_param
# vim /etc/contrail/agent_param
dev=eth4

</code></pre><p>设置vroute-agent配置:</p><pre><code># vim /etc/contrail/contrail-vrouter-agent.conf
[DEFAULT]
headless_mode=true
[DISCOVERY]
server=10.77.77.9
max_control_nodes=2
[HYPERVISOR]
type=kvm
[NETWORKS]
control_network_ip=10.77.77.15
[VIRTUAL-HOST-INTERFACE]
name=vhost0
ip=10.77.77.15/24
gateway=10.77.77.1
physical_interface=eth4

</code></pre><p>在每个OpenStack Compute节点上，配置:</p><pre><code># vim /etc/contrail/vrouter_nodemgr_param
DISCOVERY=10.77.77.9

</code></pre><p>配置nova-compute:</p><pre><code> # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_url http://10.77.77.9:9696
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_auth_url http://10.55.55.4:35357/v2.0/
 # openstack-config --set /etc/nova/nova.conf DEFAULT network_api_class nova_contrail_vif.contrailvif.ContrailNetworkAPI
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_tenant_name services
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_username neutron
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_admin_password rVlaAKUs
 # openstack-config --set /etc/nova/nova.conf DEFAULT neutron_url_timeout 300
 # openstack-config --set /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver
 # openstack-config --set /etc/nova/nova.conf DEFAULT security_group_api neutron
 # service supervisor-vrouter restart

</code></pre><p>验证所有的vrouter服务都是active状态的:</p><pre><code>root@node-18:~# contrail-status 
== Contrail vRouter ==
supervisor-vrouter:           active
contrail-vrouter-agent        active              
contrail-vrouter-nodemgr      active              

</code></pre><p>更改/etc/libvirt/qemu.confg中的cgroup_device_acl部分:</p><pre><code>cgroup_device_acl = [
&quot;/dev/null&quot;, &quot;/dev/full&quot;, &quot;/dev/zero&quot;,
&quot;/dev/random&quot;, &quot;/dev/urandom&quot;,
&quot;/dev/ptmx&quot;, &quot;/dev/kvm&quot;, &quot;/dev/kqemu&quot;,
&quot;/dev/rtc&quot;, &quot;/dev/hpet&quot;,&quot;/dev/net/tun&quot;,
]

</code></pre><p>在每个OpenStack Compute节点上，添加iptables规则如下并保存:</p><pre><code># iptables -I INPUT 1 -s 169.254.0.0/16 -i vhost0 -j ACCEPT -m comment --comment &quot;metadata service&quot;
# iptables -I INPUT 1 -p tcp -m multiport --destination-ports 2049,8085,9090,8102,33617,39704,44177,55970,60663 -j ACCEPT -m comment --comment &quot;juniper contrail rules&quot;
# iptables-save &gt; /etc/iptables/rules.v4

</code></pre><p>重启libvirt-bin和nova-compute服务:</p><pre><code># service libvirt-bin restart
# service nova-compute restart

</code></pre><p>更改vrouter的配置, ！！！注意，这是在Contrail Deploy的那个节点运行的！！！！ ：</p><pre><code># python /opt/contrail/utils/provision_vrouter.py --host_name node-18 --host_ip 10.77.77.15 --api_server_ip 10.77.77.9 --admin_user neutron --admin_password rVlaAKUs --admin_tenant_name services --oper add

</code></pre><h3 id=vgw配置>VGW配置</h3><p>OpenContrail支持多种配置，例如Juniper vSRX, Juniper MX, Cisco ASR等，但这些都需要专有硬件的支持（路由器），我们仅仅采用软件路由器Vrouter, 这里我们配置VGW:</p><pre><code># export PYTHONPATH=/usr/lib/python2.7/dist-packages/contrail_vrouter_api/gen_py/instance_service
# python /opt/contrail/utils/provision_vgw_interface.py --oper create --interface vgw --subnets 10.88.88.0/24 --routes 0.0.0.0/0 --vrf default-domain:admin:ext:ext

</code></pre><p>更新/etc/contrail/contrail-vrouter-agent.con中的[GATEWAY-0]部分:</p><pre><code>[GATEWAY-0]
routing_instance=default-domain:admin:ext:ext
interface=vgw
ip_blocks=10.88.88.0/24
routes=0.0.0.0/0

</code></pre><p>重新启动supervisor-vrouter进程:</p><pre><code># service supervisor-vrouter restart

</code></pre><p>重启其他所有的encapsulation方法，除了MPLS On UPD:<br><img src=/images/2015_04_27_22_45_01_799x306.jpg alt=/images/2015_04_27_22_45_01_799x306.jpg></p><pre><code>

好了，这时候，Contrail已经集成到OpenStack环境里，你可以在Contrail的界面里，添加上网络，而后在OpenStack里使用它。Enjoy it !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/22/shi-yong-fuelbu-shu-opencontrail-1/>使用Fuel部署OpenContrail(1)</a></h1><span class=post-date>Apr 22, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>最近在做OpenContrail的解耦合操作，因为官方提供的OpenContrail一键安装包里诸多组件都是用的默认的推荐，通过解耦合可以做到更灵活的安装和配置，有利于更方便的部署和后续的维护。所以这一系列文章是关于如何用Fuel在部署完OpenStack的基础上完成OpenContrail的部署。</p><h3 id=先决条件>先决条件</h3><p>先决条件主要是用于准备用于部署的硬件环境和软件包。<br>硬件环境:<br>i5-4460(3.2GHz/4核/6M三级缓存), 32G 内存。<br>系统:<br>Ubuntu 14.04 LTS<br>软件:</p><pre><code>$ sudo apt-get install libvirtd virt-manager

</code></pre><p>从Miranti网站下载： MirantisOpenStack-6.0.iso<br>从Contrail网站下载: contrail-install-packages_2.0-22~icehouse_all.deb<br>contrail-neutron-plugin仓库:</p><pre><code>git clone https://github.com/Juniper/contrail-neutron-plugin.git

</code></pre><h3 id=cpu内存磁盘规划>CPU/内存/磁盘规划</h3><p>需要构建一共8台虚拟机用于在部署好的Mirantis OpenStack上集成OpenContrail. CPU/内存/磁盘规划如下:<br>1台Mirantis Fuel控制节点机,2核,划分3G内存, 100G磁盘。
3个OpenStack Controller节点, 2核,各划分3G内存, 100G磁盘。<br>1个OpenStack Compute节点，2核(嵌套虚拟化),划分3G内存, 100G磁盘。<br>3个OpenContrail节点，2核,各划分4G内存, 100G磁盘。<br>一共需要27G内存。磁盘格式为qcow2，实际占用远小于这个数，各个节点最大也就是在5G左右大小。<br>其中，关于嵌套虚拟化的CPU设置，如下图, 记得选择Copy host CPU Configuration:<br><img src=/images/2015_04_27_12_20_40_598x372.jpg alt=/images/2015_04_27_12_20_40_598x372.jpg><br>启用嵌套虚拟化需要在BIOS设置，并添加相应的内核模块。</p><h3 id=网络规划>网络规划</h3><p>Fuel OpenStack规划了5个网络，分别是:<br>Admin(PXE)<br>Public<br>Management<br>Storage<br>Private</p><p>我们在Virt-Manager里也同样创建出这样的五个子网:<br>Admin(PXE) &ndash; FuelNAT &ndash; 10.20.0.0/24<br>Public &ndash; FuelPublic &ndash; 172.16.0.0/24<br>Management &ndash; FuelMgmt &ndash; 10.55.55.0/24<br>Storage &ndash; FuelStorage &ndash; 10.66.66.0/24<br>Private &ndash; FuelPrivate &ndash; 10.77.77.0/24</p><p>创建网络的步骤如下，双击Virtual Machine Manager里的localhost(QEMU), 弹出下面的窗口:<br><img src=/images/2015_04_27_14_57_37_499x379.jpg alt=/images/2015_04_27_14_57_37_499x379.jpg><br>点击网络列表最下面的+号,弹出创建网络的窗口:<br><img src=/images/2015_04_27_14_58_52_543x374.jpg alt=/images/2015_04_27_14_58_52_543x374.jpg><br>命名该网络，点击下一步:<br><img src=/images/2015_04_27_15_00_34_549x371.jpg alt=/images/2015_04_27_15_00_34_549x371.jpg><br>禁用DHCP:<br><img src=/images/2015_04_27_16_37_32_544x374.jpg alt=/images/2015_04_27_16_37_32_544x374.jpg><br>选择isolated网络模式:<br><img src=/images/2015_04_27_16_38_34_551x375.jpg alt=/images/2015_04_27_16_38_34_551x375.jpg><br>接着点击下一步直到完成，这样我们的网络就创建好了。<br>用上面的方法创建出以上5个子网。</p><h3 id=各个节点网络配置>各个节点网络配置</h3><p>Miranti Fuel Node: 仅FuelNAT, 安装完毕后，自动指定地址为10.20.0.2.<br>其他所有节点机，在创建时，把五个网络都添加上，添加方法如下:<br>Details -> Add Hardware -> Network, 而后选择:<br><img src=/images/2015_04_27_16_45_34_765x444.jpg alt=/images/2015_04_27_16_45_34_765x444.jpg></p><h3 id=miranti-fuel-node安装>Miranti Fuel Node安装</h3><p>安装很简单，直接用下载的MirantisOpenStack-6.0.iso作为安装光盘，在创建出来的虚拟机里安装系统。安装完毕后，在Host机器的浏览器里访问<br><a href=http://10.20.0.2:8000>http://10.20.0.2:8000</a><br>输入用户名密码都为admin后，登录，可以看到以下界面:<br><img src=/images/2015_04_27_16_55_29_717x477.jpg alt=/images/2015_04_27_16_55_29_717x477.jpg><br>在这个界面里我们可以进行OpenStack环境的准备、部署、配置、销毁等操作。</p><p>到这一步，我们已经完成了Miranti Fuel Node的安装，基本的部署准备工作已经完成，接下来我们将使用Fuel来部署一个可用的OpenStack环境, 以及三台用于部署Contrail的节点机.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/17/glusterfs-howto/>Glusterfs Howto</a></h1><span class=post-date>Apr 17, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>I want to expand my storage size on DigitalOcean, the droplet I have on DO one have 11G, and the other have 15G size, so if I could combine them together, I could do much more development on it. Following is how-to.</p><h3 id=glusterfs-setup>Glusterfs Setup</h3><p>Install it under Ubuntu via:</p><pre><code># apt-get install glusterfs-server

</code></pre><p>In both node, install the same software, and then add following lines into your /etc/hosts:</p><pre><code>10.17.17.195    Gluster2
10.17.17.194    Gluster1

</code></pre><p>In Gluster1, probe Gluster2:</p><pre><code>root@Gluster1:~# gluster peer probe Gluster2
peer probe: success

</code></pre><p>Then view the gluster peer status:</p><pre><code>root@Gluster1:~# gluster peer status
Number of Peers: 1

Hostname: Gluster2
Port: 24007
Uuid: 881dedb8-6cd4-4127-8c96-223daef081f5
State: Peer in Cluster (Connected)

</code></pre><p>Create the volumn via:</p><pre><code>root@Gluster1:~# gluster volume create vol_replica transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force
volume create: vol_replica: success: please start the volume to access data

</code></pre><p>Start the created vol:</p><pre><code>root@Gluster1:~# gluster volume start vol_replica
volume start: vol_replica: success

</code></pre><p>View volumn info:</p><pre><code>root@Gluster1:~# gluster volume info 
 
Volume Name: vol_replica
Type: Distribute
Volume ID: 953456f3-0c46-4d07-ac41-591d1e398be6
Status: Started
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: Gluster2:/home/glustervms
Brick2: Gluster1:/home/glustervms

</code></pre><p>Now create the folder and mount the glusterfs via:</p><pre><code>root@Gluster1:/home# mkdir glustervmsmnt
root@Gluster1:/home# mount -t glusterfs Gluster1:/vol_replica /home/glustervmsmnt/

</code></pre><p>View the disk filesystem info:</p><pre><code>Gluster1:/vol_replica   39G  4.7G   32G  13% /home/glustervmsmnt

</code></pre><h3 id=glusterfs-volumn-deletion>Glusterfs Volumn deletion</h3><p>The replica is not the one we want, for combine two partitions, I need the Distributed stripped mode, which is the one described in:<br><a href=http://www.gluster.org/community/documentation/index.php/Gluster_3.2:_Creating_Distributed_Striped_Volumes>http://www.gluster.org/community/documentation/index.php/Gluster_3.2:_Creating_Distributed_Striped_Volumes</a><br>So first I have to delete the one I&rsquo;ve created in the above part.<br>First umount the one I&rsquo;ve created:</p><pre><code>root@Gluster1:/home/glustervms# umount /home/glustervmsmnt 

</code></pre><p>checked via <code>mount</code> or <code>df -h</code> we could see the one we have mounted has been umounted.</p><p>Second, stop the volumes we&rsquo;ve created:</p><pre><code>root@Gluster1:/home/glustervms# gluster volume stop vol_replica
Stopping volume will make its data inaccessible. Do you want to continue? (y/n) y
volume stop: vol_replica: success

</code></pre><p>Third, delete volumn:</p><pre><code>root@Gluster1:/home/glustervms# gluster volume delete vol_replica
Deleting volume will erase all information about the volume. Do you want to continue? (y/n) y
volume delete: vol_replica: success

</code></pre><p>Check the volume status:</p><pre><code>root@Gluster1:/home/glustervms# gluster volume info
No volumes present

</code></pre><h3 id=create-the-distributed-stripped-volume>Create the distributed stripped volume</h3><p>Create the bigvolume:</p><pre><code>root@Gluster1:/home/glustervms# gluster volume create bigvolume transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force

</code></pre><p>Start the volume:</p><pre><code>root@Gluster1:/home/glustervms# gluster volume start bigvolume
volume start: bigvolume: success

</code></pre><p>View the status of the volume:</p><pre><code>root@Gluster1:/home/glustervmsmnt# gluster volume info 
 
Volume Name: bigvolume
Type: Distribute
Volume ID: 3e09f074-4675-46d3-873f-f00ef13fb509
Status: Started
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: Gluster2:/home/glustervms
Brick2: Gluster1:/home/glustervms

</code></pre><p>Mount it via following command:</p><pre><code># mount -t glusterfs Gluster1:/bigvolume /home/glustervmsmnt/

</code></pre><h3 id=trouble-shooting>Trouble-Shooting</h3><pre><code>root@Gluster1:/home/glustervms# gluster volume create bigvolume transport tcp Gluster2:/home/glustervms Gluster1:/home/glustervms force
volume create: bigvolume: failed: /home/glustervms or a prefix of it is already part of a volume

</code></pre><p>Resolve it via:</p><pre><code>#  apt-get install attr
#  setfattr -x trusted.glusterfs.volume-id /home/glustervms
#  setfattr -x trusted.gfid /home/glustervms
#  rm -rf /home/glustervms/.glusterfs/

</code></pre><p>Re-run the gluster volome create command it will create the volume which combines two folders.</p><h3 id=digital-ocean-scenario>Digital Ocean Scenario</h3><p>My DO droplet runs Ubuntu and CentOS, their version is Trusty(14.04) and CentOS7, so do following:</p><pre><code>CentOS # wget -P /etc/yum.repos.d http://download.gluster.org/pub/gluster/glusterfs/LATEST/CentOS/glusterfs-epel.repo
CentOS # yum -y install glusterfs glusterfs-fuse glusterfs-server
CentOS # systemctl start glusterd
CentOS # systemctl enable glusterd
Trusty # apt-get install glusterfs-server

</code></pre><p>Add each other&rsquo;s name and ip address into /etc/hosts, make sure they could ping each other and get responsible:</p><pre><code>1xx.xx.xxx.xxx	CentOS
1xx.xx.xxx.xx	Trusty

</code></pre><p>Use Trusty as the server, so on the Trusty machine, detect the CentOS&rsquo;s glusterd configuration as:</p><pre><code>Trusty # gluster peer probe CentOS
peer probe: success

</code></pre><p>Check the status:</p><pre><code>Trusty # gluster peer status
Number of Peers: 1

Hostname: CentOS
Port: 24007
Uuid: xxxxxxxx
State: Peer in Cluster (Connected)

</code></pre><p>Create the bigvolume, and mount it into your own directory via:</p><pre><code>Trusty # gluster volume create bigvolume transport tcp CentOS:/home/glustervms Trusty:/home/glustervms force
volume create: bigvolume: success: please start the volume to access data
Trusty # gluster volume start bigvolume
volume start: bigvolume: success
Trusty # gluster volume info
 
Volume Name: bigvolume
Type: Distribute
Volume ID: xxxxxxxxxxxxxxxxxxxxx
Status: Started
Number of Bricks: 2
Transport-type: tcp
Bricks:
Brick1: CentOS:/home/glustervms
Brick2: Trusty:/home/glustervms
Trusty # mkdir /home/glustervmsmnt/
Trusty # mount -t glusterfs Trusty:/bigvolume /home/glustervmsmnt/
Trusty # df -h
Filesystem              Size  Used Avail Use% Mounted on
/dev/vda1                20G  9.4G  9.2G  51% /
none                    4.0K     0  4.0K   0% /sys/fs/cgroup
udev                    235M  8.0K  235M   1% /dev
tmpfs                    50M  396K   49M   1% /run
none                    5.0M     0  5.0M   0% /run/lock
none                    246M  1.1M  244M   1% /run/shm
none                    100M     0  100M   0% /run/user
Trusty:/bigvolume       40G   14G   24G  37% /home/glustervmsmnt

</code></pre><p>Now you could operate under the /home/glustervmsmnt and you have 24G size partion of the disk. Enjoy them!!!</p><h3 id=trouble-shooting-1>Trouble-Shooting 1</h3><p>If you met <code>File change as we read it</code> in tar something, do following things:</p><pre><code>Trusty # gluster volume set bigvolume performance.stat-prefetch off
volume set: success

</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/16/build-fuel-icehouse-iso/>Build fuel icehouse iso</a></h1><span class=post-date>Apr 16, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>Fuel6.0 didn&rsquo;t support icdhouse by default, so we have to build it manually, the steps are listed as following:</p><pre><code>apt-get install git
mkdir ~/fuel
cd ~/fuel
git clone https://github.com/stackforge/fuel-main.git
cd fuel-main
 ./prepare-build-env.sh
export MIRROR_BASE=http://mirror.fuel-infra.org/fwm/6.0-icehouse
make iso

</code></pre><p>After making the iso which have icehouse will be available.</p><h3 id=troubleshooting>TroubleShooting</h3><p>Some modifications should be made before we make them:</p><pre><code>Trusty@ubuntu1204:~/code/fuel6.0/fuel-main$ git checkout stable/6.0
Branch stable/6.0 set up to track remote branch stable/6.0 from origin.
Switched to a new branch 'stable/6.0'
Trusty@ubuntu1204:~/code/fuel6.0/fuel-main$ git branch
  master
* stable/6.0

</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/16/quickly-play-puppet/>Quickly play puppet</a></h1><span class=post-date>Apr 16, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=server-and-client>Server and Client</h3><p>In server, install following packages:</p><pre><code>$ sudo apt-get install puppet puppetmaster

</code></pre><p>In client, only install puppet is enough.<br>After installation, added the each other&rsquo;s name into <code>/etc/hosts</code>, let them ping each other via name rather than via ip address.</p><h3 id=sign>Sign</h3><p>In client, do following:</p><pre><code>$ clouder@pc121:/etc/puppet$ puppet agent --test --server=pc119
Exiting; no certificate found and waitforcert is disabled

</code></pre><p>Then in server, listed all of the certification request:</p><pre><code>root@pc119:~/Code/herokublog# sudo puppet cert list
  &quot;pc121&quot; (SHA256) 28:23:36:3C:E4:8B:3A:15:D2:B0:8C:A2:BC:E9:A1:E5:6A:6F:76:0E:40:73:29:1F:8F:8C:D4:83:1F:92:4F:C7

</code></pre><p>sign the cert:</p><pre><code>root@pc119:~/Code/herokublog# sudo puppet cert sign pc121
Notice: Signed certificate request for pc121
Notice: Removing file Puppet::SSL::CertificateRequest pc121 at '/var/lib/puppet/ssl/ca/requests/pc121.pem'

</code></pre><p>Verify it in the client:</p><pre><code>clouder@pc121:/etc/puppet$ puppet agent --test
Warning: Unable to fetch my node definition, but the agent run will continue:
Warning: getaddrinfo: Name or service not known
Info: Retrieving plugin
Error: /File[/home/clouder/.puppet/var/lib]: Failed to generate additional resources using 'eval_generate': getaddrinfo: Name or service not known

</code></pre><h3 id=configuration>Configuration</h3><p>TBD</p></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/155/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/155/>155</a></li><li class="page-item active"><a class=page-link href=/page/156/>156</a></li><li class=page-item><a class=page-link href=/page/157/>157</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/244/>244</a></li><li class=page-item><a href=/page/157/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/244/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>