<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/14/an-zhuang-icehouse-at-ubuntu14-dot-04-7/>安装Icehouse@Ubuntu14.04(7)</a></h1><span class=post-date>Apr 14, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>接下来在OpenStack Icehouse的基础上，部署OpenContrail, OpenContrail能提供更为强大的网络功能。<br>首先从Juniper的官网上下载安装文件:</p><pre><code>	contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb

</code></pre><p>Contrail可以被安装到已经部署好的OpenStack环境中，只要在安装Contrail的时候，根据已有的OpenStack组件的部署情况作相应的调整就可以。</p><h3 id=hook>Hook</h3><p>Contrail用到的钩子(Hook)有：<br><code>core_plugin</code> &ndash; 它被用在neutron的配置中，用于指向ContrailPlugin组件。<br><code>libvirt_vif_driver</code> &ndash; 它被用在nova计算节点配置中，用来指向Contrail的VRouterVIFDriver.<br><code>MQ broker IP and Port</code> &ndash; 如果现有的OpenStack提供RabbitMQ那么将相应的IP和端口在neutron和nova的配置中指过去。</p><h3 id=contrial部署涉及组建>Contrial部署涉及组建</h3><p>列举如下，对应的文件需要做修改，或者创建。</p><pre><code>api_service.conf - This file needs to be edited to provide details of existing OpenStack keystone.
plugin.ini - This file needs proper keystone URL, token and credentials.
neutron.conf - This file needs auth_host credentials to connect OpenStack keystone.
config.global.js - This file contains IP and PORT for image (glance), compute (nova), identity (keystone), storage (cinder)
OpenStack controller nova config to point to Contrail neutron
OpenStack controller neuron service endpoint to point to contrail neutron.

</code></pre><p>为了让来之不易的OpenStack不至于被毁掉，建议先做好备份。因为接下来就要对已经部署好的节点做各种操作了。</p><h3 id=干掉ovs>干掉OVS</h3><p>Make sure to remove existing OpenStack OVS installed modules and config.
首先，在DashBoard里干掉所有的网络配置(网络/路由等）。</p><h4 id=network节点移除openvswitch>Network节点移除OpenVSwitch</h4><p>更改Network节点的网络配置，取消br-ex的配置：</p><pre><code>root@JunoNetwork:~# vim /etc/network/interfaces
auto eth2
iface eth2 inet static
address 10.22.22.212
netmask 255.255.255.0

#iface eth2 inet manual
#iface br-ex inet static
#address 10.22.22.212
#netmask 255.255.255.0
## gateway 10.22.22.1
#bridge_ports eth2
#bridge_stp off
#auto br-ex

</code></pre><p>移除br-ex设备，并重启Network节点:</p><pre><code>root@JunoNetwork:~# ovs-vsctl del-port br-ex eth2
root@JunoNetwork:~# ovs-vsctl del-br br-ex
root@JunoNetwork:~# reboot

</code></pre><p>注释掉关于ML2服务配置并重新启动服务：</p><pre><code>root@JunoNetwork:~# cat /etc/neutron/plugins/ml2/ml2_conf.ini| grep -i &quot;^###&quot;
### type_drivers = flat,gre
### tenant_network_types = gre
### mechanism_drivers = openvswitch
### tunnel_id_ranges = 1:1000
### enable_security_group = True
### firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
### enable_security_group = True
### [ovs]
### local_ip = 10.19.19.212
### tunnel_type = gre
### enable_tunneling = True
root@JunoNetwork:~# service openvswitch-switch restart

</code></pre><p>注释掉关于metadata的相关配置：</p><pre><code>root@JunoNetwork:~# cat /etc/neutron/metadata_agent.ini | grep -i &quot;^###&quot;
### auth_url = http://10.17.17.211:5000/v2.0
### auth_region = regionOne
### admin_tenant_name = service
### admin_user = neutron
### admin_password = engine
### nova_metadata_ip = 10.17.17.211
### metadata_proxy_shared_secret = engine

</code></pre><p>回到Controller节点，同样注释掉metadata的配置:</p><pre><code>root@JunoController:~# cat /etc/nova/nova.conf | grep -i &quot;^###&quot;
### service_neutron_metadata_proxy = true
### metadata_proxy_shared_secret = engine
### neutron_metadata_proxy_shared_secret = engine

</code></pre><p>移除DHCP相关配置：</p><pre><code>root@JunoNetwork:~# cat /etc/neutron/dhcp_agent.ini | grep -i &quot;^###&quot;
### interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
### dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
### use_namespaces = True
### dnsmasq_config_file = /etc/neutron/dnsmasq-neutron.conf
root@JunoNetwork:~# cat /etc/neutron/dnsmasp-neutron.conf | grep -i &quot;^###&quot;
### dhcp-option-force=26,1454

</code></pre><p>移除L3 agent:</p><pre><code>root@JunoNetwork:~# cat /etc/neutron/l3_agent.ini | grep -i &quot;^###&quot;
### interface_driver = neutron.agent.linux.interface.OVSInterfaceDriver
### use_namespaces = True
### verbose = True

</code></pre><p>移除neutron通用组件的支持:</p><pre><code>root@JunoNetwork:~# cat /etc/neutron/neutron.conf | grep -i &quot;^###&quot;
### rpc_backend = neutron.openstack.common.rpc.impl_kombu
### rabbit_host = 10.17.17.211
### rabbit_password = engine
### core_plugin = ml2
### service_plugins = router
### allow_overlapping_ips = True
### verbose = True
### auth_strategy = keystone
### auth_uri = http://10.17.17.211:5000
### auth_host = 10.17.17.211
### auth_port = 35357
### auth_protocol = http
### admin_tenant_name = service
### admin_user = neutron
### admin_password = engine

</code></pre><p>移除已经安装的vswitch相关的包:</p><pre><code>root@JunoNetwork:~# apt-get purge neutron-plugin-ml2 neutron-plugin-openvswitch-agent neutron-l3-agent neutron-dhcp-agent
root@JunoCompute:~# apt-get purge openvswitch-common openvswitch-switch
root@JunoCompute:~# reboot

</code></pre><h4 id=compute节点移除openvswitch>Compute节点移除OpenVSwitch</h4><p>Compute节点的服务移除：</p><pre><code>root@JunoCompute:~# cat /etc/neutron/neutron.conf | grep -i &quot;^###&quot;
[DEFAULT]
###auth_strategy = keystone
###rpc_backend = neutron.openstack.common.rpc.impl_kombu
###rabbit_host = 10.17.17.211
###rabbit_password = engine
###core_plugin = ml2
###service_plugins = router
###allow_overlapping_ips = True
###verbose = True
[keystone_authtoken]
### auth_uri = http://10.17.17.211:5000
### auth_host = 10.17.17.211
### auth_port = 35357
### auth_protocol = http
### admin_tenant_name = service
### admin_user = neutron
### admin_password = engine
### signing_dir = $state_path/keystone-signing
root@JunoCompute:~# cat /etc/neutron/plugins/ml2/ml2_conf.ini | grep -i &quot;^###&quot;
### type_drivers = gre
### tenant_network_types = gre
### mechanism_drivers = openvswitch
### tunnel_id_ranges = 1:1000
### firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
### enable_security_group = True
### [ovs]
### local_ip = 10.19.19.213
### tunnel_type = gre
### enable_tunneling = True

</code></pre><p>注释完毕后，重新启动服务:</p><pre><code>root@JunoCompute:~# service nova-compute restart
root@JunoCompute:~# service neutron-plugin-openvswitch-agent restart
root@JunoCompute:~# service openvswitch-switch restart

</code></pre><p>Compute节点上的nova不再使用neutron作为网络管理器:</p><pre><code>root@JunoCompute:~# cat /etc/nova/nova.conf | grep -i &quot;^###&quot;
### network_api_class = nova.network.neutronv2.api.API
### neutron_url = http://10.17.17.211:9696
### neutron_auth_strategy = keystone
### neutron_admin_tenant_name = service
### neutron_admin_username = neutron
### neutron_admin_password = engine
### neutron_admin_auth_url = http://10.17.17.211:35357/v2.0
### linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
### firewall_driver = nova.virt.firewall.NoopFirewallDriver
### security_group_api = neutron
root@JunoCompute:~# service nova-compute restart

</code></pre><p>在Compute节点上,移除已经安装的openvswitch的包:</p><pre><code>root@JunoCompute:~# apt-get purge neutron-plugin-ml2 neutron-plugin-openvswitch-agent openvswitch-datapath-dkms
root@JunoCompute:~# apt-get purge openvswitch-common openvswitch-switch
root@JunoCompute:~# reboot

</code></pre><p>检查状态,确保服务已经被移除:</p><pre><code>root@JunoCompute:~# service openvswitch-switch status
openvswitch-switch: unrecognized service
root@JunoCompute:~# service neutron-plugin-openvswitch-agent status
neutron-plugin-openvswitch-agent: unrecognized service

</code></pre><h4 id=controller节点上移除openvswitch>Controller节点上移除OpenVSwitch</h4><p>移除nova配置中关于neutron的条目：</p><pre><code>root@JunoController:~# cat /etc/nova/nova.conf | grep -i &quot;^###&quot;
### service_neutron_metadata_proxy = true
### metadata_proxy_shared_secret = engine
### neutron_metadata_proxy_shared_secret = engine
### network_api_class = nova.network.neutronv2.api.API
### neutron_url = http://10.17.17.211:9696
### neutron_auth_strategy = keystone
### neutron_admin_tenant_name = service
### neutron_admin_username = neutron
### neutron_admin_password = engine
### neutron_admin_auth_url = http://10.17.17.211:35357/v2.0
### linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver
### firewall_driver = nova.virt.firewall.NoopFirewallDriver
### security_group_api = neutron

</code></pre><p>移除对于ML2插件的支持:</p><pre><code>root@JunoController:~# cat /etc/neutron/plugins/ml2/ml2_conf.ini | grep -i &quot;^###&quot;
### type_drivers = flat,gre
### tenant_network_types = gre
### mechanism_drivers = openvswitch
### tunnel_id_ranges = 1:1000
### firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
### enable_security_group = True

</code></pre><p>移除neutron中配置:</p><pre><code>root@JunoController:~# cat /etc/neutron/neutron.conf | grep -i &quot;^###&quot;
### rpc_backend = neutron.openstack.common.rpc.impl_kombu
### rabbit_host = 10.17.17.211
### rabbit_password = engine
### notify_nova_on_port_status_changes = True
### notify_nova_on_port_data_changes = True
### nova_url = http://10.17.17.211:8774/v2
### nova_admin_username = nova
### nova_admin_tenant_id = 4b22bf4e6a68419aa91da6e0ffaca2dc
### nova_admin_password = engine
### nova_admin_auth_url = http://10.17.17.211:35357/v2.0
### nova_region_name = regionOne
### core_plugin = ml2
### service_plugins = router
### allow_overlapping_ips = True
### auth_strategy = keystone
### auth_uri = http://10.17.17.211:5000
### auth_host = 10.17.17.211
### auth_port = 35357
### auth_protocol = http
### admin_tenant_name = service
### admin_user = neutron
### admin_password = engine
### connection = mysql://neutron:engine@10.17.17.211/neutron

</code></pre><p>删除ml2插件:</p><pre><code>root@JunoController:~# apt-get purge neutron-plugin-ml2

</code></pre><p>测试，由于连验证都没法通过，所以会返回错误，当然你的DashBoard也会有错误,暂时没办法访问了。:</p><pre><code>root@JunoController:~#  neutron agent-list
Authentication required

</code></pre><h3 id=contrail>Contrail</h3><h4 id=创建机器>创建机器</h4><p>4G内存，2核CPU，同时连接到所有网络(10.17.17.0/24, 10.19.19.0/24, 10.22.22.0/24):</p><pre><code>[root:/home/juju/img/OpenStack]# qemu-img create -f qcow2 -b ./UbuntuBase1404.qcow2  JunoContrail.qcow2

</code></pre><p>配置网络接口, hosts, hostname等:</p><pre><code>root@JunoContrail:~# cat /etc/hostname 
JunoContrail
root@JunoContrail:~# cat /etc/hosts
10.17.17.211    JunoController
10.17.17.212    JunoNetwork
10.17.17.213    JunoCompute
10.17.17.214    JunoContrail
root@JunoContrail:~# cat /etc/network/interfaces
auto lo
iface lo inet loopback

# The primary network interface
auto eth0
iface eth0 inet static
address 10.17.17.214
netmask 255.255.255.0
gateway 10.17.17.1
dns-nameservers 114.114.114.114

# Network, have the tunnel, which locates at the 10.19.19.0/24
auto eth1
iface eth1 inet static
address 10.19.19.214
netmask 255.255.255.0
up route add -net 10.19.19.0/24 dev eth1

auto eth2
iface eth2 inet static
address 10.22.22.214
netmask 255.255.255.0

</code></pre><p>得到包，并且安装之:</p><pre><code>root@JunoContrail:~# wget http://xxxxxxxxxxxxxx/contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb 
root@JunoContrail:~# dpkg -i contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb 


</code></pre><p>直接安装会出错，为了避免，直接手动安装build-essential和python-pip:</p><pre><code>root@JunoContrail:~# apt-get install build-essential python-pip

</code></pre><p>而后手动开始安装contrail:</p><pre><code>root@JunoContrail:/opt/contrail/contrail_packages# ./setup.sh 

</code></pre><p>使用模板生成testbed.py文件:</p><pre><code>root@JunoContrail:/opt/contrail# cp /opt/contrail/utils/fabfile/testbeds/testbed_multibox_example.py /opt/contrail/utils/fabfile/testbeds/testbed.py

</code></pre><p>需要配置ntp，加入到本地的NTP网络里:</p><pre><code>root@JunoContrail:/opt/contrail/utils# apt-get -y install ntp
root@JunoContrail:/opt/contrail/utils# vim /etc/ntp.conf 
server 10.17.17.211 iburst
root@JunoContrail:/opt/contrail/utils# service ntp restart
 * Stopping NTP server ntpd
   ...done.
ntpq * Starting NTP server ntpd
   ...done.
root@JunoContrail:/opt/contrail/utils# ntpq -c peers
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 JunoController  202.112.29.82    3 u    1   64    1    0.312   33.463   0.000

</code></pre><p>配置testbed.py文件，更改后的例子如下：</p><pre><code>TBD........

</code></pre><p>安装的时候，出现问题，需要切换到最旧的原始安装的Ubuntu1404. 切换前，记下已有的步骤:</p><pre><code>$ cd /opt/contrail/utils/
$ fab install_pkg_all:/root/contrail-install-packages_2.10-39~ubuntu-14-04icehouse_all.deb 
$ fab -c fabrc install_without_openstack:no

</code></pre><p>切换:</p><pre><code>[root:/home/juju/img/OpenStack]# mv JunoContrail.qcow2 JunoContrail.qcow2_Deploy_Failed_Too_new


</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-1/>安装Icehouse@Ubuntu14.04(1)</a></h1><span class=post-date>Apr 13, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>项目的需要，手动基于多台Ubuntu虚拟机部署OpenStack Icehouse, 然后在部署好的Icehouse的基础上，部署OpenContrail, 最终达到OpenContrail解耦的过程。</p><h3 id=环境准备>环境准备</h3><p>物理机: i7-3770/24G Memory/CentOS 6.6<br>软件: virt-manager/qemu等<br>节点机(虚拟机):<br>节点机1: 控制节点(JunoController), 2 CPU+3G内存+单网卡(管理网络,10.17.17.211).<br>节点机2: 网络节点(JunoNetwork), 1 CPU+1G内存+3 网卡(管理网络:10.17.17.212, GRE Tunnel网络:10.19.19.212, 外部网络:10.22.22.212).<br>节点机3: 计算节点(JunoCompute), 2 CPU(Nested)+2G内存+2 网卡(管理网络:10.17.17.213, GRE Tunnel网络:10.19.19.213).<br>网络配置:<br>Virt-manager里需要配置三个网络，一个是管理网络10.17.17.0/24, 另一个GRE Tunnel网络10.19.19.0/24, 外部网络为10.22.22.0/24.<br>参考资料:<br>不错的指南文件:<a href=http://godleon.github.io/blog/2015/02/10/install-openstack-juno-in-ubuntu-basic-environment-setting/>http://godleon.github.io/blog/2015/02/10/install-openstack-juno-in-ubuntu-basic-environment-setting/</a><br>官方文档:<a href=http://docs.openstack.org/icehouse/install-guide/install/apt/content/>http://docs.openstack.org/icehouse/install-guide/install/apt/content/</a></p><h3 id=虚拟机准备>虚拟机准备</h3><p>用以下命令创建三台虚拟机的磁盘，而后按照上面的节点机配置完毕后，启动三台虚拟机。</p><pre><code># pwd
/home/juju/img/OpenStack
# qemu-img create -f qcow2 -b ./UbuntuBase1404.qcow2 JunoController.qcow2
# qemu-img create -f qcow2 -b ./UbuntuBase1404.qcow2 JunoNetwork.qcow2
# qemu-img create -f qcow2 -b ./UbuntuBase1404.qcow2 JunoCompute.qcow2

</code></pre><p>更改节点机的/etc/hostname文件，更改各自的名字为JunoController, JunoNetwork和JunoCompute.<br>每台机器的/etc/network/interfaces文件配置如下:<br>JunoController:</p><pre><code># The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
auto eth0
iface eth0 inet static
address 10.17.17.211
netmask 255.255.255.0
gateway 10.17.17.1
dns-nameservers 114.114.114.114

</code></pre><p>JunoNetwork:</p><pre><code># The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
# auto eth0
# iface eth0 inet dhcp

# The primary network interface
auto eth0
iface eth0 inet static
address 10.17.17.212
netmask 255.255.255.0
#gateway 10.17.17.1
dns-nameservers 114.114.114.114

# Network, have the tunnel, which locates at the 10.19.19.0/24
auto eth1
iface eth1 inet static
address 10.19.19.212
netmask 255.255.255.0
up route add -net 10.19.19.0/24 dev eth1

# Directly to internet, used for ovs
auto eth2
iface eth2 inet dhcp

</code></pre><p>JunoCompute:</p><pre><code># The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
auto eth0
iface eth0 inet static
address 10.17.17.213
netmask 255.255.255.0
gateway 10.17.17.1
dns-nameservers 114.114.114.114

# Network, have the tunnel, which locates at the 10.19.19.0/24
auto eth1
iface eth1 inet static
address 10.19.19.213
netmask 255.255.255.0
up route add -net 10.19.19.0/24 dev eth1

</code></pre><p>把下列条目添加到各台节点机的 /etc/hosts文件中:</p><pre><code>10.17.17.211    JunoController
10.17.17.212    JunoNetwork
10.17.17.213    JunoCompute

</code></pre><h3 id=ntp服务部署>NTP服务部署</h3><h4 id=ntp-服务器>NTP 服务器</h4><p>使用NTP来保证各个节点之间的时间同步，对后续加入的各个节点，同样需要使用NTP来同步该节点时间。我们将JunoController作为NTP服务器,在JunoController上，安装和配置NTP服务器：</p><pre><code>root@JunoController:~# apt-get -y install ntp
root@JunoController:~# vim /etc/ntp.conf
    # 修改成大陆时间
    server 2.cn.pool.ntp.org
    server 1.asia.pool.ntp.org
    server 2.asia.pool.ntp.org
    # 修改 restrict 設定
    restrict -4 default kod notrap nomodify
    restrict -6 default kod notrap nomodify
root@JunoController:~# service ntp restart

</code></pre><h4 id=ntp客户端>NTP客户端</h4><p>其他的节点上都需要安装NTP客户端并使用NTP服务器时间同步。</p><pre><code># apt-get -y install ntp
# vim /etc/ntp.conf
    # 設定 controller 為參照的 time server
    # 並將其他 server 開頭的設定進行註解
    server 10.17.17.211 iburst
# service ntp restart

</code></pre><p>检查结果是否正确:</p><pre><code>root@JunoNetwork:~# ntpq -c peers
     remote           refid      st t when poll reach   delay   offset  jitter
==============================================================================
 JunoController  59.106.180.168   3 u    1   64    1    0.239  447024.   0.049

</code></pre><h3 id=添加软件仓库>添加软件仓库</h3><p>官方文档中说icehouse已经在14.04的官方仓库中了，所以下面的步骤并不是必须的。<br>在所有节点上，执行以下操作:</p><pre><code># apt-get install python-software-properties
# add-apt-repository cloud-archive:icehouse
# apt-get update &amp;&amp; apt-get -y dist-upgrade &amp;&amp; reboot

</code></pre><h3 id=安装配置数据库>安装/配置数据库</h3><p>OpenStack需要一个数据库用于存储相关数据，一般情况下采用MySQL. &ldquo;你问我支持不支持MySQL？我说不支持，我就明确告诉你，你们呀，我感觉你们开源界也要学习，你们非常熟悉MYSQL被Oracle这一套的，你们毕竟是Too Young，明白这意思吗？"&mdash;-所以装一个MariaDB来代替它.</p><pre><code>root@JunoController:~# apt-get -y install mariadb-server python-mysqldb
root@JunoController:~# vim /etc/mysql/my.cnf 
    [mysqld]
    # 修改 bind-address 設定
    bind-address = 10.17.17.211
    
    # 加入以下 UTF-8 的相關設定
    default-storage-engine = innodb
    innodb_file_per_table
    collation-server = utf8_general_ci
    init-connect = 'SET NAMES utf8'
    character-set-server = utf8

</code></pre><p>重启服务:</p><pre><code>root@JunoController:~# service mysql restart

</code></pre><h3 id=安装消息服务器>安装消息服务器</h3><p>同样在控制节点上安装，OpenStack使用rabbitmq作为消息服务器：</p><pre><code>root@JunoController:~# apt-get install -y rabbitmq-server

</code></pre><p>修改初始化guest密码:</p><pre><code>root@JunoController:~# rabbitmqctl change_password guest RABBITMQ_PASSWD

</code></pre><p>第一部分跑完，这里我们完成了OpenStack创建的基本设定，接下来就可以挨个搭建OpenStack的服务了。</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-2/>安装Icehouse@Ubuntu14.04(2)</a></h1><span class=post-date>Apr 13, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=安装identity服务>安装Identity服务</h3><p>首先创建keystone所需数据库:</p><pre><code>root@JunoController:~# mysql -u root -p
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 28
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; CREATE DATABASE keystone;
Query OK, 1 row affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'KEYSTONE_PASS';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'KEYSTONE_PASS';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; exit;
Bye

</code></pre><p>安装keystone相关套件:</p><pre><code>root@JunoController:~# apt-get -y install keystone python-keystoneclient

</code></pre><p>创建一个admin token用于做初始化配置:</p><pre><code>root@JunoController:~# openssl rand -hex 10
5c3b5cd66a7dfa8e33e5

</code></pre><p>使用上面取得的admin token和mysql设置用于更新/etc/keystone.conf文件，更改如下:</p><pre><code>root@JunoController:~# vim /etc/keystone/keystone.conf 
[DEFAULT]
admin_token=5c3b5cd66a7dfa8e33e5
verbose=True
log_dir = /var/log/keystone

[database]
connection=mysql://keystone:KEYSTONE_DBPASS@10.17.17.211/keystone



</code></pre><p>部署数据库并重新启动Keystone服务:</p><pre><code>root@JunoController:~# su -s /bin/sh -c &quot;keystone-manage db_sync&quot; keystone
root@JunoController:~# service keystone restart

</code></pre><p>删除不需要的sqlite数据库, 并设定crontab任务:</p><pre><code>root@JunoController:~# rm -f /var/lib/keystone/keystone.db
root@JunoController:~# (crontab -l -u keystone 2&gt;&amp;1 | grep -q token_flush) || echo '@hourly /usr/bin/keystone-manage token_flush &gt;/var/log/keystone/keystone-tokenflush.log 2&gt;&amp;1' &gt;&gt; /var/spool/cron/crontabs/keystone

</code></pre><h3 id=建立-user--role--tenant>建立 user / role / tenant</h3><p>环境变量设置:</p><pre><code>root@JunoController:~# export OS_SERVICE_TOKEN=5c3b5cd66a7dfa8e33e5
root@JunoController:~# export OS_SERVICE_ENDPOINT=http://10.17.17.211:35357/v2.0

</code></pre><h4 id=tenant创建>tenant创建</h4><p>创建admin tenant:</p><pre><code>root@JunoController:~#  keystone tenant-create --name admin --description &quot;Admin Tenant&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |           Admin Tenant           |
|   enabled   |               True               |
|      id     | ea1f0a6b15dc4796958f087c38756ed1 |
|     name    |              admin               |
+-------------+----------------------------------+

</code></pre><p>创建demo tenant:</p><pre><code>root@JunoController:~# keystone tenant-create --name demo --description &quot;Demo Tenant&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |           Demo Tenant            |
|   enabled   |               True               |
|      id     | 2ac9cae777014d3d94458f521b013e94 |
|     name    |               demo               |
+-------------+----------------------------------+

</code></pre><h4 id=建立user>建立user</h4><p>建立admin用户:</p><pre><code>root@JunoController:~# keystone user-create --name admin --pass xxxx --email kkkttt@gmail.com
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |        kkkttt@gmail.com        |
| enabled  |               True               |
|    id    | 055dd9b7b1564df5bf9e9c511f32978b |
|   name   |              admin               |
| username |              admin               |
+----------+----------------------------------+

</code></pre><p>在demo tenant下建立demo用户:</p><pre><code>root@JunoController:~# keystone user-create --name demo --tenant demo --pass engine --email kkkttt@gmail.com
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |        kkkttt@gmail.com        |
| enabled  |               True               |
|    id    | e8f2c2bdaee34f3895147f26a924e010 |
|   name   |               demo               |
| tenantId | 2ac9cae777014d3d94458f521b013e94 |
| username |               demo               |
+----------+----------------------------------+

</code></pre><h4 id=admin-role>admin role</h4><p>建立admin role:</p><pre><code>root@JunoController:~# keystone role-create --name admin
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|    id    | 4af914913e154a599deb1b78a0751c1a |
|   name   |              admin               |
+----------+----------------------------------+

</code></pre><h4 id=链接userroletenant>链接user/role/tenant</h4><pre><code>root@JunoController:~# keystone user-role-add --user admin --tenant admin --role admin

</code></pre><h4 id=创建一个service-tenant>创建一个Service Tenant</h4><p>先建立Service Tenant:</p><pre><code>root@JunoController:~# keystone tenant-create --name service --description &quot;Service Tenant&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |          Service Tenant          |
|   enabled   |               True               |
|      id     | 4b22bf4e6a68419aa91da6e0ffaca2dc |
|     name    |             service              |
+-------------+----------------------------------+

</code></pre><h4 id=定义services--api-服务挂载点>定义services & API 服务挂载点</h4><p>所有安装好的服务都需要向Identity Service注册，甚至是Identity Service本身，都需要先注册上才可以被使用:<br>首先注册Identity Service:</p><pre><code>root@JunoController:~# keystone service-create --name keystone --type identity --description &quot;OpenStack Identity&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |        OpenStack Identity        |
|   enabled   |               True               |
|      id     | 27bf7f70deac429d8d28623d99939ae6 |
|     name    |             keystone             |
|     type    |             identity             |
+-------------+----------------------------------+

</code></pre><p>而后，设定Identity Service的服务端点:</p><pre><code>root@JunoController:~# keystone endpoint-create --service-id $(keystone service-list | awk '/ identity / {print $2}') --publicurl http://10.17.17.211:5000/v2.0 --internalurl http://10.17.17.211:5000/v2.0 --adminurl http://10.17.17.211:35357/v2.0 --region regionOne                      
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
|   adminurl  |  http://10.17.17.211:35357/v2.0  |
|      id     | fb4c17d5c1414a7e852c6f7db552dd89 |
| internalurl |  http://10.17.17.211:5000/v2.0   |
|  publicurl  |  http://10.17.17.211:5000/v2.0   |
|    region   |            regionOne             |
|  service_id | 27bf7f70deac429d8d28623d99939ae6 |
+-------------+----------------------------------+

</code></pre><p>验证Identity服务是否安装成功,首先，unset环境变量:</p><pre><code>root@JunoController:~# unset OS_SERVICE_TOKEN OS_SERVICE_ENDPOINT

</code></pre><p>以 tenant(admin) & user(admin) 的身份取得 token:</p><pre><code>keystone --os-tenant-name admin --os-username admin --os-password ADMIN_PASS --os-auth-url http://10.17.17.211:35357/v2.0 token-get

</code></pre><p>以 tenant(admin) & user(admin) 的身分查詢 tenant 清單:</p><pre><code># keystone --os-tenant-name admin --os-username admin --os-password  xxxxxx --os-auth-url http://10.17.17.211:35357/v2.0 tenant-list
+----------------------------------+---------+---------+
|                id                |   name  | enabled |
+----------------------------------+---------+---------+
| ea1f0a6b15dc4796958f087c38756ed1 |  admin  |   True  |
| 2ac9cae777014d3d94458f521b013e94 |   demo  |   True  |
| 4b22bf4e6a68419aa91da6e0ffaca2dc | service |   True  |
+----------------------------------+---------+---------+

</code></pre><p>查询user清单：</p><pre><code>root@JunoController:~# keystone --os-tenant-name admin --os-username admin --os-password xxxx --os-auth-url http://10.17.17.211:35357/v2.0 user-list
+----------------------------------+-------+---------+--------------------+
|                id                |  name | enabled |       email        |
+----------------------------------+-------+---------+--------------------+
| 055dd9b7b1564df5bf9e9c511f32978b | admin |   True  | kkkttt@gmail.com |
| e8f2c2bdaee34f3895147f26a924e010 |  demo |   True  | kkkttt@gmail.com |
+----------------------------------+-------+---------+--------------------+

</code></pre><p>查询role清单:</p><pre><code>root@JunoController:~# keystone --os-tenant-name admin --os-username admin --os-password xxxx --os-auth-url http://10.17.17.211:35357/v2.0 role-list
+----------------------------------+----------+
|                id                |   name   |
+----------------------------------+----------+
| 9fe2ff9ee4384b1894a90878d3e92bab | _member_ |
| 4af914913e154a599deb1b78a0751c1a |  admin   |
+----------------------------------+----------+

</code></pre><p>以demo用户身份去的token</p><pre><code>root@controller:~# keystone --os-tenant-name demo --os-username demo --os-password DEMO_PASS --os-auth-url http://10.17.17.211:35357/v2.0 token-get

</code></pre><p>以demo身份取得用户清单会被提示权限不足:</p><pre><code>root@JunoController:~# keystone --os-tenant-name demo --os-username demo --os-password xxxx --os-auth-url http://10.17.17.211:35357/v2.0 user-list
You are not authorized to perform the requested action, admin_required. (HTTP 403)

</code></pre><p>现在keystone服务已经挂载完毕了，接下来就是逐个挂载组件。</p><h3 id=快速切换脚本>快速切换脚本</h3><p>快速切换脚本如下，记得加上执行权限:</p><pre><code>root@JunoController:~# cat openstack/admin-openrc.sh
export OS_TENANT_NAME=admin
export OS_USERNAME=admin
export OS_PASSWORD=xxxx
export OS_AUTH_URL=http://10.17.17.211:35357/v2.0
root@JunoController:~# cat openstack/demo-openrc.sh 
export OS_TENANT_NAME=demo
export OS_USERNAME=demo
export OS_PASSWORD=xxxx
export OS_AUTH_URL=http://10.17.17.211:5000/v2.0

</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-3/>安装Icehouse@Ubuntu14.04(3)</a></h1><span class=post-date>Apr 13, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>Image Service 用于提供给用户用于快速启动虚拟机的镜像文件，这样的服务称为glance服务。</p><h3 id=glance服务数据库设定>Glance服务数据库设定</h3><p>在mysql中创建glance数据库:</p><pre><code>root@JunoController:~#  mysql -u root -p
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 33
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; CREATE DATABASE glance;
Query OK, 1 row affected (0.01 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' IDENTIFIED BY 'xxxx'
    -&gt; ;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY 'xxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; quit;
Bye

</code></pre><h3 id=创建glance的userroletenant权限>创建Glance的user/role/tenant权限</h3><p>用admin的权限，创建以下权限：</p><pre><code>root@JunoController:~#  source ~/openstack/admin-openrc.sh

</code></pre><p>创建glance用户:</p><pre><code>root@JunoController:~# keystone user-create --name glance --pass engine
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | c706febbcc8843fb97383c9fdfba6214 |
|   name   |              glance              |
| username |              glance              |
+----------+----------------------------------+

</code></pre><p>用户glance属于admin角色，使用service tanant:</p><pre><code>keystone user-role-add --user glance --tenant service --role admin

</code></pre><p>在keystone注册glance服务:</p><pre><code>root@JunoController:~# keystone service-create --name glance --type image --description &quot;OpenStack Image Service&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |     OpenStack Image Service      |
|   enabled   |               True               |
|      id     | 3d52d2992b9f423eb9868304e4405fab |
|     name    |              glance              |
|     type    |              image               |
+-------------+----------------------------------+

</code></pre><p>在keystone创建服务的end-point:</p><pre><code>root@JunoController:~# keystone endpoint-create --service-id $(keystone service-list | awk '/ image / {print $2}') --publicurl http://10.17.17.211:9292 --internalurl http://10.17.17.211:9292 --adminurl http://10.17.17.211:9292 --region regionOne
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
|   adminurl  |     http://10.17.17.211:9292     |
|      id     | f44400bebc07408d8e0f4e70a0d18475 |
| internalurl |     http://10.17.17.211:9292     |
|  publicurl  |     http://10.17.17.211:9292     |
|    region   |            regionOne             |
|  service_id | 3d52d2992b9f423eb9868304e4405fab |
+-------------+----------------------------------+

</code></pre><h3 id=安装glance服务>安装Glance服务</h3><p>安装:</p><pre><code>apt-get -y install glance python-glanceclient

</code></pre><p>配置:</p><pre><code># vim /etc/glance/glance-api.conf
[database]
# sqlite_db = /var/lib/glance/glance.sqlite
backend = sqlalchemy
connection = mysql://glance:engine@10.17.17.211/glance

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = glance
admin_password = engine
#  vim /etc/glance/glance-registry.conf
[database]
# The file name to use with SQLite (string value)
#sqlite_db = /var/lib/glance/glance.sqlite
backend = sqlalchemy
connection = mysql://glance:engine@10.17.17.211/glance

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = glance
admin_password = engine
# rm -f /var/lib/glance/glance.sqlite
# su -s /bin/sh -c &quot;glance-manage db_sync&quot; glance

</code></pre><p>这里会碰到一个问题，解决方案如下:</p><pre><code>root@JunoController:~# su -s /bin/sh -c &quot;glance-manage db_sync&quot; glance
2015-04-13 17:20:22.637 9455 CRITICAL glance [-] ValueError: Tables &quot;migrate_version&quot; have non utf8 collation, please make sure all tables are CHARSET=utf8

root@JunoController:~# mysql -u root -p glance
Enter password: 
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 29
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [glance]&gt; alter table migrate_version convert to character set utf8 collate utf8_unicode_ci;
Query OK, 1 row affected (0.09 sec)                
Records: 1  Duplicates: 0  Warnings: 0

MariaDB [glance]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

MariaDB [glance]&gt; quit;
Bye

</code></pre><p>重启服务，</p><pre><code>root@JunoController:~# service glance-registry restart
root@JunoController:~# service glance-api restart

</code></pre><h3 id=验证glance服务>验证Glance服务</h3><p>首先下载镜像:</p><pre><code># wget http://cdn.download.cirros-cloud.net/0.3.3/cirros-0.3.3-x86_64-disk.img

</code></pre><p>创建Glance可见镜像:</p><pre><code># glance image-create --name &quot;cirros-0.3.3-x86_64&quot; --file cirros-0.3.3-x86_64-disk.img --disk-format qcow2 --container-format bare --is-public True --progress
[=============================&gt;] 100%
+------------------+--------------------------------------+
| Property         | Value                                |
+------------------+--------------------------------------+
| checksum         | 133eae9fb1c98f45894a4e60d8736619     |
| container_format | bare                                 |
| created_at       | 2015-04-13T09:27:54                  |
| deleted          | False                                |
| deleted_at       | None                                 |
| disk_format      | qcow2                                |
| id               | 68f14900-8b25-4329-ad56-8fbd497c6812 |
| is_public        | True                                 |
| min_disk         | 0                                    |
| min_ram          | 0                                    |
| name             | cirros-0.3.3-x86_64                  |
| owner            | ea1f0a6b15dc4796958f087c38756ed1     |
| protected        | False                                |
| size             | 13200896                             |
| status           | active                               |
| updated_at       | 2015-04-13T09:27:54                  |
| virtual_size     | None                                 |
+------------------+--------------------------------------+

</code></pre><p>检查镜像:</p><pre><code>root@JunoController:~# ls /var/lib/glance/images/
68f14900-8b25-4329-ad56-8fbd497c6812

</code></pre><p>列出可用镜像:</p><pre><code>root@JunoController:~# glance image-list
+--------------------------------------+---------------------+-------------+------------------+----------+--------+
| ID                                   | Name                | Disk Format | Container Format | Size     | Status |
+--------------------------------------+---------------------+-------------+------------------+----------+--------+
| 68f14900-8b25-4329-ad56-8fbd497c6812 | cirros-0.3.3-x86_64 | qcow2       | bare             | 13200896 | active |
+--------------------------------------+---------------------+-------------+------------------+----------+--------+

</code></pre><p>好了，现在glance服务可以使用了，接下来将创建compute节点和网络节点。</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2015/04/13/an-zhuang-icehouse-at-ubuntu14-dot-04-4/>安装Icehouse@Ubuntu14.04(4)</a></h1><span class=post-date>Apr 13, 2015<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>这里将配置计算节点。计算节点我们使用了一台2G内存的虚拟机，并使用了嵌套虚拟化，可以通过<code>lscpu</code>来看到CPU的VMX/VT-X标志都已经被下发到虚拟机中。</p><h3 id=数据库准备>数据库准备</h3><p>使用下列命令来创建nova所需数据库:</p><pre><code>root@JunoController:~# mysql -u root -p
Enter password: 
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MariaDB connection id is 35
Server version: 5.5.41-MariaDB-1ubuntu0.14.04.1 (Ubuntu)

Copyright (c) 2000, 2014, Oracle, MariaDB Corporation Ab and others.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

MariaDB [(none)]&gt; CREATE DATABASE nova;
Query OK, 1 row affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'xxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'xxxx';
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; flush privileges;
Query OK, 0 rows affected (0.00 sec)

MariaDB [(none)]&gt; quit
Bye

</code></pre><h3 id=nova用户>nova用户</h3><p>创建nova用户:</p><pre><code>root@JunoController:~# source ~/openstack/admin-openrc.sh
root@JunoController:~# keystone user-create --name nova --pass xxxx
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
|  email   |                                  |
| enabled  |               True               |
|    id    | 845c22d1a781458a8b28ba54534b73dd |
|   name   |               nova               |
| username |               nova               |
+----------+----------------------------------+

</code></pre><p>制定nova属于service tenant, 并赋予admin权限:</p><pre><code>root@JunoController:~# keystone user-role-add --user nova --tenant service --role admin

</code></pre><p>在keystone注册nova:</p><pre><code>root@JunoController:~# keystone service-create --name nova --type compute --description &quot;OpenStack Compute&quot;
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description |        OpenStack Compute         |
|   enabled   |               True               |
|      id     | 8733caba0b9742a39ee9ac53ad4d8e27 |
|     name    |               nova               |
|     type    |             compute              |
+-------------+----------------------------------+

</code></pre><p>在keystone注册nova end-point:</p><pre><code>root@JunoController:~# keystone endpoint-create --service-id $(keystone service-list | awk '/ compute / {print $2}') --publicurl http://10.17.17.211:8774/v2/%\(tenant_id\)s --internalurl http://10.17.17.211:8774/v2/%\(tenant_id\)s --adminurl http://10.17.17.211:8774/v2/%\(tenant_id\)s --region regionOne
+-------------+-------------------------------------------+
|   Property  |                   Value                   |
+-------------+-------------------------------------------+
|   adminurl  | http://10.17.17.211:8774/v2/%(tenant_id)s |
|      id     |      d16c91bfacf2474ebee36314535a146f     |
| internalurl | http://10.17.17.211:8774/v2/%(tenant_id)s |
|  publicurl  | http://10.17.17.211:8774/v2/%(tenant_id)s |
|    region   |                 regionOne                 |
|  service_id |      8733caba0b9742a39ee9ac53ad4d8e27     |
+-------------+-------------------------------------------+

</code></pre><h3 id=compute服务安装>Compute服务安装</h3><h4 id=controller节点配置>Controller节点配置</h4><p>在Controller节点上，安装以下包:</p><pre><code>root@JunoController:~# apt-get -y install nova-api nova-cert nova-conductor nova-consoleauth nova-novncproxy nova-scheduler python-novaclient

</code></pre><p>配置nova所需的配置文件:</p><pre><code># vim /etc/nova/nova.conf
[database]
connection = mysql://nova:xxxxx@10.17.17.211/nova

[DEFAULT]
....
rpc_backend = rabbit
rabbit_host = 10.17.17.211
rabbit_password = xxxxxx
my_ip=10.17.17.211
vncserver_listen = 0.0.0.0
vncserver_proxyclient_address = 10.17.17.211
auth_strategy = keystone 

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = nova
admin_password = xxxx
[glance]
host=10.17.17.211

</code></pre><p>删除sqlite3数据库:</p><pre><code>root@JunoController:~# rm /var/lib/nova/nova.sqlite 

</code></pre><p>创建数据库：</p><pre><code>root@JunoController:~# su -s /bin/sh -c &quot;nova-manage db sync&quot; nova

</code></pre><p>重启服务，使用nova检查本机可用镜像情况:</p><pre><code>root@JunoController:~# service nova-api restart
root@JunoController:~# service nova-cert restart
root@JunoController:~#  service nova-consoleauth restart
root@JunoController:~# service nova-scheduler restart
root@JunoController:~# service nova-conductor restart
root@JunoController:~# service nova-novncproxy restart
root@JunoController:~# nova image-list
+--------------------------------------+---------------------+--------+--------+
| ID                                   | Name                | Status | Server |
+--------------------------------------+---------------------+--------+--------+
| 68f14900-8b25-4329-ad56-8fbd497c6812 | cirros-0.3.3-x86_64 | ACTIVE |        |
+--------------------------------------+---------------------+--------+--------+

</code></pre><h4 id=compute节点安装>Compute节点安装</h4><p>安装下列包:</p><pre><code>root@JunoCompute:~#  apt-get -y install nova-compute sysfsutils

</code></pre><p>配置:</p><pre><code>root@JunoCompute:~# vim /etc/nova/nova.conf 
[DEFAULT]
......
auth_strategy = keystone
rpc_backend = rabbit
rabbit_host = 10.17.17.211
rabbit_password = xxxx
my_ip = 10.17.17.213
vnc_enabled = True
vncserver_listen = 0.0.0.0
vncserver_proxyclient_address = 10.17.17.213
novncproxy_base_url = http://10.17.17.211:6080/vnc_auto.html
glance_host = 10.17.17.211

[keystone_authtoken]
auth_uri = http://10.17.17.211:5000
auth_host = 10.17.17.211
auth_port = 35357
auth_protocol = http
admin_tenant_name = service
admin_user = nova
admin_password = xxxx

[database]
#The SQLAlchemy connection string used to connect to the database
connection = mysql://nova:xxxx@10.17.17.211/nova
[glance]
host=10.17.17.211

</code></pre><p>看cpu硬件是否支持硬件加速:</p><pre><code>root@JunoCompute:~# egrep -c '(vmx|svm)' /proc/cpuinfo
2

</code></pre><p>如果支持加速，则配置nova-compute.conf为:</p><pre><code>root@JunoCompute:~# cat /etc/nova/nova-compute.conf
[libvirt]
virt_type=kvm

</code></pre><p>删除不需要的nova.sqlite文件:</p><pre><code>root@JunoCompute:~# rm -f /var/lib/nova/nova.sqlite 

</code></pre><p>重起nova服务:</p><pre><code>root@JunoCompute:~# service nova-compute restart

</code></pre><h3 id=验证>验证</h3><p>在控制节点上,列出所有的service:</p><pre><code>root@JunoController:~# nova service-list
+------------------+----------------+----------+---------+-------+----------------------------+-----------------+
| Binary           | Host           | Zone     | Status  | State | Updated_at                 | Disabled Reason |
+------------------+----------------+----------+---------+-------+----------------------------+-----------------+
| nova-cert        | JunoController | internal | enabled | up    | 2015-04-13T10:16:10.000000 | -               |
| nova-consoleauth | JunoController | internal | enabled | up    | 2015-04-13T10:16:12.000000 | -               |
| nova-scheduler   | JunoController | internal | enabled | up    | 2015-04-13T10:16:05.000000 | -               |
| nova-conductor   | JunoController | internal | enabled | up    | 2015-04-13T10:16:08.000000 | -               |
| nova-compute     | JunoCompute    | nova     | enabled | up    | 2015-04-13T10:16:09.000000 | -               |
+------------------+----------------+----------+---------+-------+----------------------------+-----------------+

</code></pre><p>现在compute节点已经配置完了，接下来可以配置网络节点。配置完网络节点后，就可以启动虚拟机了。</p></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/146/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/146/>146</a></li><li class="page-item active"><a class=page-link href=/page/147/>147</a></li><li class=page-item><a class=page-link href=/page/148/>148</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/234/>234</a></li><li class=page-item><a href=/page/148/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/234/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>