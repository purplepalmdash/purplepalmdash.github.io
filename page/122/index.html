<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta name=generator content="Hugo 0.64.0"><link href=http://gmpg.org/xfn/11 rel=profile><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Dash &#183; Dash</title><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/poole-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-overrides.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/hyde-a.css?ref=abc124"><link rel=stylesheet href="https://purplepalmdash.github.io/css/custom-additions.css?ref=abc124"><link rel=stylesheet href=https://purplepalmdash.github.io/css/highlight/googlecode.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/styles/docco.min.css><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/jquery/1.10.2/jquery.min.js></script><script type=text/javascript src=/js/html2canvas.js></script><script type=text/javascript>function genPostShot(){var rightNow=new Date();var imageName=rightNow.toISOString().slice(0,16).replace(/(-)|(:)|(T)/g,"");imageName+='.jpg'
html2canvas(document.getElementsByClassName('post'),{background:'#FFFFFF',onrendered:function(canvas){$('#test').attr('href',canvas.toDataURL("image/jpeg"));$('#test').attr('download',imageName);$('#test')[0].click();}});};</script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js></script><script>hljs.initHighlightingOnLoad();</script><link rel=apple-touch-icon-precomposed sizes=144x144 href="http://purplepalmdash.github.io/touch-icon-144-precomposed.png?ref=abc124"><link href="http://purplepalmdash.github.io/favicon.png?ref=abc124" rel=icon><link href=%7balternate%20%7bRSS%20application/rss+xml%20%20index%20alternate%20%20false%20false%20true%20false%20false%200%7d%20/index.xml%20http://purplepalmdash.github.io/index.xml%7d rel=alternate type=application/rss+xml title="Dash &#183; Dash"><meta name=description content><meta name=keywords content="unix,virtualization,embedded,linux"></head><body class=theme-base-0c><div class=sidebar><div class="container sidebar-sticky"><div class=sidebar-about><img src=http://purplepalmdash.github.io/images/mylogo.jpeg alt=gravatar><h1><a href=http://purplepalmdash.github.io/>很惭愧，就做了一点微小的工作</a></h1><a href=http://purplepalmdash.github.io/><p>Dash</p></a></div><ul class=sidebar-nav><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/post/>All Posts</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/technology/>Technology</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/life/>Life</a></li><li class=sidebar-nav-item><a href=http://purplepalmdash.github.io/categories/linuxtips/>LinuxTips</a></li></ul><ul class=sidebar-nav><li class=sidebar-nav-item><a href=https://github.com/purplepalmdash><i class="fa fa-github-square fa-3x"></i></a><a href=https://cn.linkedin.com/in/yang-feipeng-1b909319><i class="fa fa-linkedin-square fa-3x"></i></a><a href=https://plus.google.com/u/0/106572959364703833986><i class="fa fa-google-plus-square fa-3x"></i></a><a href=https://www.facebook.com/yang.feipeng><i class="fa fa-facebook-square fa-3x"></i></a><a href=https://twitter.com/dashwillfly><i class="fa fa-twitter-square fa-3x"></i></a></li></ul></div></div><div class="content container"><div class=posts><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2016/07/01/xenserver-statistics/>XenServer Statistics</a></h1><span class=post-date>Jul 1, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><p>Direct write rrd into graphite, refers to:</p><pre><code>$ git clone https://github.com/jgilmour/XenGraphiteIT.git
</code></pre><p>Then you get the storage pool information fro xsconsole via:</p><pre><code>$ xe vdi-list
</code></pre><p>Notice it will contain the hard disk and iso repositories, use harddisk.</p><p>Now edit the .config file:</p><pre><code>[XENAPI]
URL = http://192.168.10.187
USERNAME = root
PASSWORD = xxxxxxx
SR-UUID = 51977c4b-8dc2-bcff-b7ad-de7cc5c7e717

[GRAPHITE]
CARBON_HOST = 192.168.1.79
CARBON_PORT = 2003
CARBON_NAME = collectd.com.IT.servers.xen.
</code></pre><p>Run <code>python2 xengraphite.py</code> you could get your XenServer statistic data into your
graphite database, enjoy it.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2016/06/29/site-to-site-vpn/>site-to-site VPN</a></h1><span class=post-date>Jun 29, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=reference>Reference</h3><p>Refers to:</p><p><a href=https://clauseriksen.net/2011/02/02/ipsec-on-debianubuntu/>https://clauseriksen.net/2011/02/02/ipsec-on-debianubuntu/</a><br>And
<a href=http://xmodulo.com/create-site-to-site-ipsec-vpn-tunnel-openswan-linux.html>http://xmodulo.com/create-site-to-site-ipsec-vpn-tunnel-openswan-linux.html</a></p><h3 id=network-topology>Network Topology</h3><p>The topology is listed as following:</p><p>Host1 &ndash; LAN1 &ndash; Router1 &ndash;[BIG, BAD INTERNET]&ndash; Router2 &ndash; LAN2 &ndash; Host2</p><p>Router1 and Router2 are Ubuntu14.04 machine, which runs in virt-manager,thus you have
to create 2 new networks, each in one physical machine.</p><p>Physical Machine 1: 192.168.1.79<br>Router1:<br>eth0: bridge to physical machine&rsquo;s networking. 192.168.10.100<br>eth1: 10.47.70.2.<br>DHCP on eth1.</p><p>Physical Machine 2: 192.168.1.69<br>Router2:<br>eth0: bridge to physical machine&rsquo;s networking. 192.168.10.200<br>eth1: 10.47.67.2.<br>DHCP on eth1.</p><h3 id=router-network-configuration>Router Network Configuration</h3><p>Router1&rsquo;s networking configuration:</p><pre><code>$ vim /etc/network/interfaces
    # The loopback network interface
    auto lo
    iface lo inet loopback
    
    # The primary network interface
    auto eth0
    iface eth0 inet static
    address 192.168.10.100
    netmask 255.255.0.0
    gateway 192.168.0.176
    dns-nameservers 223.5.5.5
    
    auto eth1
    iface eth1 inet static
    address 10.47.70.2
    netmask 255.255.255.0
</code></pre><p>Router2&rsquo;s networking configuration:</p><pre><code>$ vim /etc/network/interfaces
    # The loopback network interface
    auto lo
    iface lo inet loopback
    
    # The primary network interface
    auto eth0
    iface eth0 inet static
    address 192.168.10.200
    netmask 255.255.0.0
    gateway 192.168.0.176
    dns-nameservers 223.5.5.5
    auto eth1
    iface eth1 inet static
    address 10.47.67.2
    netmask 255.255.255.0
</code></pre><p>After configuration , restart the Router1 and Router2.</p><h3 id=ipsec-configuration>IPSEC Configuration</h3><h4 id=router1>Router1</h4><p>Install following package:</p><pre><code>$ sudo apt-get install -y openswan
</code></pre><p>Append following lines at the end of <code>/etc/sysctl.conf</code>,then run <code>sysctl -p /etc/sysctl.conf</code> to take effects.</p><pre><code>$ vim /etc/sysctl.conf
net.ipv4.ip_forward=1
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.all.send_redirects = 0
net.ipv4.conf.default.send_redirects = 0
net.ipv4.conf.eth0.send_redirects = 0
net.ipv4.conf.default.accept_redirects = 0
net.ipv4.conf.eth0.accept_redirects = 0
</code></pre><p>Also you have to disable the redirects via following commands:</p><pre><code>for vpn in /proc/sys/net/ipv4/conf/*;
do echo 0 &gt; $vpn/accept_redirects;
echo 0 &gt; $vpn/send_redirects;
done
</code></pre><p>iptables rules should be done via following:</p><pre><code>iptables -A INPUT -p udp --dport 500 -j ACCEPT
iptables -A INPUT -p tcp --dport 4500 -j ACCEPT
iptables -A INPUT -p udp --dport 4500 -j ACCEPT
iptables -t nat -A POSTROUTING -s 10.47.70.0/24 -d 10.47.67.0/24 -j SNAT --to 192.168.10.100
#iptables -t nat -A POSTROUTING -s site-A-private-subnet -d site-B-private-subnet -j SNAT --to site-A-Public-IP
iptables -A POSTROUTING -t nat -d 10.47.70.0/24 -o eth1 -m policy --dir out --pol ipsec -j ACCEPT
iptables -A INPUT -m policy --dir in --pol ipsec -j ACCEPT
iptables -A INPUT -p udp -m multiport --dports 500,4500 -j ACCEPT
iptables -A INPUT -p esp -j ACCEPT
iptables -A FORWARD -m policy --dir in --pol ipsec -j ACCEPT
</code></pre><p>Now continue to configure the ipsec:</p><pre><code>$ sudo vim /etc/ipsec.conf
    ## general configuration parameters ##
     
    config setup
            plutodebug=all
            plutostderrlog=/var/log/pluto.log
            protostack=netkey
            nat_traversal=yes
            virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12
            ## disable opportunistic encryption in Red Hat ##
            oe=off
     
    ## disable opportunistic encryption in Debian ##
    ## Note: this is a separate declaration statement ##
    #include /etc/ipsec.d/examples/no_oe.conf 
     
    ## connection definition in Debian ##
    conn demo-connection-debian
            authby=secret
            auto=start
            ## phase 1 ##
            keyexchange=ike
            ## phase 2 ##
            esp=3des-md5
            pfs=yes
            type=tunnel
            left=192.168.10.100
            leftsourceip=192.168.10.100
            leftsubnet=10.47.70.0/24
            ## for direct routing ##
            #leftsubnet=192.168.10.100/32
            #leftnexthop=%defaultroute
            leftnexthop=192.168.10.200
            right=192.168.10.200
            rightsubnet=10.47.67.0/24
</code></pre><p>Notice the left/right configuration, should corresponding the our definition
of the networking.</p><p>Now generate the pre-shared keys via:</p><pre><code>$ dd if=/dev/random count=24 bs=1 | xxd -ps
24+0 records in
24+0 records out
24 bytes copied, 4.5529e-05 s, 527 kB/s
cece1b0ffe27f82c27efc94339f08c418abb9e5f5c0d5bf5
</code></pre><p>the <code>cece1b0ffe27f82c27efc94339f08c418abb9e5f5c0d5bf5</code> is the keys we want to
fill into the secrets:</p><pre><code>$ sudo cat /etc/ipsec.secrets 
    # This file holds shared secrets or RSA private keys for inter-Pluto
    # authentication.  See ipsec_pluto(8) manpage, and HTML documentation.
    
    # RSA private key for this host, authenticating it to any other host
    # which knows the public part.  Suitable public keys, for ipsec.conf, DNS,
    # or configuration of other implementations, can be extracted conveniently
    # with &quot;ipsec showhostkey&quot;.
    
    # this file is managed with debconf and will contain the automatically created RSA keys
    include /var/lib/openswan/ipsec.secrets.inc
    192.168.10.100  192.168.10.200:  PSK  &quot;cece1b0ffe27f82c27efc94339f08c418abb9e5f5c0d5bf5&quot;
</code></pre><p>Now Router1 is configured, we continue to configure Router2.</p><h4 id=router2>Router2</h4><p>Ipsec and sysctl are the same as in Router1, the iptables scripts is listed as:</p><pre><code>iptables -A INPUT -p udp --dport 500 -j ACCEPT
iptables -A INPUT -p tcp --dport 4500 -j ACCEPT
iptables -A INPUT -p udp --dport 4500 -j ACCEPT
iptables -t nat -A POSTROUTING -s 10.47.67.0/24 -d 10.47.70.0/24 -j SNAT --to 192.168.10.200

#iptables -A POSTROUTING -t nat -d 192.168.1.0/24 -o eth0 -m policy --dir out --pol ipsec -j ACCEPT
iptables -A POSTROUTING -t nat -d 10.47.67.0/24 -o eth1 -m policy --dir out --pol ipsec -j ACCEPT
iptables -A INPUT -m policy --dir in --pol ipsec -j ACCEPT
iptables -A INPUT -p udp -m multiport --dports 500,4500 -j ACCEPT
iptables -A INPUT -p esp -j ACCEPT
iptables -A FORWARD -m policy --dir in --pol ipsec -j ACCEPT
</code></pre><p>Now configure the ipsec.conf like following:</p><pre><code>$ sudo vim /etc/ipsec.conf
## general configuration parameters ##
 
config setup
        plutodebug=all
        plutostderrlog=/var/log/pluto.log
        protostack=netkey
        nat_traversal=yes
        virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12
        ## disable opportunistic encryption in Red Hat ##
        oe=off
 
## disable opportunistic encryption in Debian ##
## Note: this is a separate declaration statement ##
#include /etc/ipsec.d/examples/no_oe.conf 
 
## connection definition in Debian ##
conn demo-connection-debian
        authby=secret
        auto=start
        ## phase 1 ##
        keyexchange=ike
        ## phase 2 ##
        esp=3des-md5
        pfs=yes
        type=tunnel
        left=192.168.10.200
        leftsourceip=192.168.10.200
        leftsubnet=10.47.67.0/24
        ## for direct routing ##
        #leftsubnet=192.168.10.200/32
        #leftnexthop=%defaultroute
        leftnexthop=192.168.10.100
        right=192.168.10.100
        rightsubnet=10.47.70.0/24
</code></pre><p>Notice the definition&rsquo;s differences comparing to Router1.</p><p>The ipsec.secrets is the same as Router1, but you have to change like following:</p><pre><code>$ sudo vim /etc/ipsec.secrets
192.168.10.200  192.168.10.100:  PSK  &quot;3030804556207bde9fc5c9a043c6ac13fce136ce41eb98a6&quot;
</code></pre><h3 id=examine>Examine</h3><p>Restart the ipsec services on both Router.</p><pre><code>$ sudo  /etc/init.d/ipsec restart
</code></pre><p>Examine the route via:</p><pre><code>adminubuntu@vpn1:~$ ip route
default via 192.168.0.176 dev eth0 
10.47.67.0/24 dev eth0  scope link  src 192.168.10.100 
10.47.70.0/24 dev eth1  proto kernel  scope link  src 10.47.70.2 
192.168.0.0/16 dev eth0  proto kernel  scope link  src 192.168.10.100 
adminubuntu@vpn2:~$ ip route
default via 192.168.0.176 dev eth0 
10.47.67.0/24 dev eth1  proto kernel  scope link  src 10.47.67.2 
10.47.70.0/24 dev eth0  scope link  src 192.168.10.200 
192.168.0.0/16 dev eth0  proto kernel  scope link  src 192.168.10.200 
</code></pre><p>So we can see the route shows the connection of the vpn.</p><p>Now examine the ipsec status:</p><pre><code>$ sudo service ipsec status
IPsec running  - pluto pid: 930
pluto pid 930
1 tunnels up
some eroutes exist
</code></pre><p>More detailed infos could be examine via: <code>sudo ipsec auto --status</code>.</p><h3 id=dhcp-server>DHCP Server</h3><p>Install dhcpd and configure it via following command:</p><pre><code>$ sudo apt-get install -y isc-dhcp-server
$ sudo vim /etc/default/isc-dhcp-server
INTERFACES=&quot;eth1&quot;
</code></pre><p>Append following lines to <code>/etc/dhcp/dhcpd.conf</code>:<br>Router1:</p><pre><code>subnet
10.47.70.0 netmask 255.255.255.0 {
# --- default gateway
option routers
10.47.70.2;
# --- Netmask
option subnet-mask
255.255.255.0;
# --- Broadcast Address
option broadcast-address
10.47.70.255;
# --- Domain name servers, tells the clients which DNS servers to use.
option domain-name-servers
223.5.5.5,180.76.76.76;
option time-offset 0;
range 10.47.70.3 10.47.70.254;
default-lease-time 1209600;
max-lease-time 1814400;
}
</code></pre><p>Router2:</p><pre><code>subnet
10.47.67.0 netmask 255.255.255.0 {
# --- default gateway
option routers
10.47.67.2;
# --- Netmask
option subnet-mask
255.255.255.0;
# --- Broadcast Address
option broadcast-address
10.47.67.255;
# --- Domain name servers, tells the clients which DNS servers to use.
option domain-name-servers
223.5.5.5,180.76.76.76;
option time-offset 0;
range 10.47.67.3 10.47.67.254;
default-lease-time 1209600;
max-lease-time 1814400;
}
</code></pre><p>Now your subnet is ready, restart the Router1 and Router2, next step we will
verify our site-to-site VPN.</p><h3 id=verification>Verification</h3><p>Create 2 new vm on 2 physical machine, each of them attached to our Router&rsquo;s
eth1 networking. I use tinycore for experiment.</p><p>Tinycore Attaches to Router1:<br><img src=/images/2016_06_29_19_23_50_469x212.jpg alt=/images/2016_06_29_19_23_50_469x212.jpg><br>Tinycore Attaches to Router2:<br><img src=/images/2016_06_29_19_25_18_497x351.jpg alt=/images/2016_06_29_19_25_18_497x351.jpg></p><p>The picture also shows the ping each other without any problem.</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2016/06/20/da-jian-ji-yu-dockerde-jian-kong-xi-tong/>搭建基于docker的监控系统</a></h1><span class=post-date>Jun 20, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=graphitegrafana>Graphite/Grafana</h3><p>这两个用于记录和展示监控数据，通过以下命令可以快速搭建:</p><h4 id=graphite>Graphite</h4><p>开启容器:</p><pre><code>$ mkdir -p /local/path/to/graphite/storage/whisper/
$ sudo docker run -d \
  --name graphite \
  -p 8080:80 \
  -p 2003:2003 \
  -v /local/path/to/.htpasswd:/etc/nginx/.htpasswd \
  -v /local/path/to/graphite/storage/whisper:/opt/graphite/storage/whisper \
  sitespeedio/graphite
</code></pre><p>创建htpasswd文件的方法可以参阅:<br><a href=http://httpd.apache.org/docs/2.2/programs/htpasswd.html>http://httpd.apache.org/docs/2.2/programs/htpasswd.html</a></p><p>当然如果你使用默认的密码的话，用户名/密码是:guest/guest.</p><h4 id=grafana>Grafana</h4><p>开启容器:</p><pre><code># mkdir -p /local/path/to/grafana
# docker run -d -p 3000:3000 --name=grafana -v /local/path/to/grafana:/var/lib/grafana  grafana/grafana
</code></pre><p>默认用户名/密码为admin/admin.</p><h3 id=collectd>Collectd</h3><p>用于采集节点机上的数据，</p><pre><code># docker run -d --net=host --privileged -v /:/hostfs:ro --name=collectd -e \
HOST_NAME=localhost -e \
GRAPHITE_HOST=192.168.1.79 andreasjansson/collectd-write-graphite
</code></pre><p>参数说明:</p><pre><code>--net=host : 	使用主机上的网络配置
GRAPHITE_HOST:  前面设置的graphite机器的地址
</code></pre><h3 id=systemd-启动方式>systemd 启动方式</h3><p>collectd启动方式:</p><pre><code>$ sudo vim /usr/lib/systemd/system/collectddocker.service
[Unit]
Description=collectd container
Requires=docker.service
After=docker.service

[Service]
Restart=always
ExecStart=/usr/bin/docker start -a collectd
ExecStop=/usr/bin/docker stop -t 2 collectd

[Install]
WantedBy=multi-user.target
</code></pre><p>启动并使能服务:</p><pre><code>$ sudo systemctl enable collectddocker.service
</code></pre></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2016/06/18/da-jian-wu-pan-centoszhuo-mian-huan-jing/>搭建无盘CentOS桌面环境</a></h1><span class=post-date>Jun 18, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=网络准备>网络准备</h3><p>创建一个无DHCP的网络:</p><p><img src=/images/2016_06_18_13_53_06_399x429.jpg alt=/images/2016_06_18_13_53_06_399x429.jpg></p><p>DHCP服务器我们将配置在PXE服务器节点上。</p><h3 id=pxe节点配置>PXE节点配置</h3><h4 id=初始化配置>初始化配置</h4><p>最小化安装CentOS 7 Server。并配置其IP地址为<code>10.19.20.2</code>.<br>关闭selinux和firewalld服务:</p><pre><code># vi /etc/selinux/config 
SELINUX=disabled

# systemctl disable firewalld.service
</code></pre><h4 id=使用dvd作为源>使用DVD作为源</h4><p>创建挂载目录并挂在DVD：</p><pre><code># mkdir /cdrom
# mount -t iso9660 -o loop ./CentOS-7-x86_64-Everything-1511.iso /cdrom/
</code></pre><p>创建新的repo文件:</p><pre><code># vi /etc/yum.repos.d/local.repo

[LocalRepo]
name=Local Repository
baseurl=file:///cdrom
enabled=1
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
</code></pre><p>生成新的缓存：</p><pre><code># mkdir back
# mv CentOS-* back
# yum makecache
</code></pre><p>安装一些必要的包:</p><pre><code># yum install -y vim wget
</code></pre><h4 id=tftp-server>TFTP Server</h4><p>安装必要的包:</p><pre><code># yum -y install syslinux xinetd tftp-server
# mkdir /var/lib/tftpboot/pxelinux.cfg 
# cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ 
</code></pre><p>配置PXE：</p><pre><code># vim /etc/xinetd.d/tftp 
disable = no
# systemctl start xinetd
# systemctl enable xinetd
</code></pre><h4 id=dhcp服务器>DHCP服务器</h4><p>安装:</p><pre><code># yum install -y dhcp
</code></pre><p>配置:</p><pre><code># vim /etc/dhcp/dhcpd.conf
    #
    # DHCP Server Configuration file.
    #   see /usr/share/doc/dhcp*/dhcpd.conf.example
    #   see dhcpd.conf(5) man page
    #
    # create new
    
    # specify domain name
    option domain-name &quot;srv.world&quot;;
    # specify name server's hostname or IP address
    option domain-name-servers dlp.srv.world;
    # default lease time
    default-lease-time 600;
    # max lease time
    max-lease-time 7200;
    # this DHCP server to be declared valid
    authoritative;
    # specify network address and subnet mask
    subnet 10.19.20.0 netmask 255.255.255.0 {
        # specify the range of lease IP address
        range dynamic-bootp 10.19.20.200 10.19.20.254;
        # specify broadcast address
        option broadcast-address 10.19.20.255;
        # specify default gateway
        option routers 10.19.20.1;
        option domain-name-servers   10.19.20.2;
        filename        &quot;pxelinux.0&quot;;
        next-server     10.19.20.2;
    }
</code></pre><p>启动并使能服务:</p><pre><code># systemctl start dhcpd 
# systemctl enable dhcpd 
</code></pre><h4 id=pxe服务器>PXE服务器</h4><p>安装一些必要的包:</p><pre><code># yum -y install dracut-network nfs-utils
</code></pre><p>在PXE服务器上构建一个无盘系统用的文件系统</p><pre><code># mkdir -p /var/lib/tftpboot/centos7/root 
# yum groups -y install &quot;Server with GUI&quot; --releasever=7 --installroot=/var/lib/tftpboot/centos7/root/
</code></pre><p>给出root用户的默认密码:</p><pre><code># python -c 'import crypt,getpass; \ 
print(crypt.crypt(getpass.getpass(), \
crypt.mksalt(crypt.METHOD_SHA512)))' 
Password:
xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
</code></pre><p>填入root密码到/etc/shadown中:</p><pre><code># vim /var/lib/tftpboot/centos7/root/etc/shadow
root:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:16372:0:99999:7:::
</code></pre><p>构建<code>/etc/fstab</code>文件:</p><pre><code># vi /var/lib/tftpboot/centos7/root/etc/fstab
 none    /tmp        tmpfs   defaults   0 0
tmpfs   /dev/shm    tmpfs   defaults   0 0
sysfs   /sys        sysfs   defaults   0 0
proc    /proc       proc    defaults   0 0
</code></pre><p>下载pxe所需要的vmlinuz和initrd.img文件:</p><pre><code># wget -P /var/lib/tftpboot/centos7/ \
http://mirrors.aliyun.com/centos/7/os/x86_64/images/pxeboot/vmlinuz \
http://mirrors.aliyun.com/centos/7/os/x86_64/images/pxeboot/initrd.img
</code></pre><p>创建默认的pxe启动项目:</p><pre><code># vi /var/lib/tftpboot/pxelinux.cfg/default
# create new
 default centos7

label centos7
    kernel centos7/vmlinuz
    append initrd=centos7/initrd.img root=nfs:10.19.20.2:/var/lib/tftpboot/centos7/root rw selinux=0 
</code></pre><p>映射NFS服务器:</p><pre><code># vi /etc/exports
/var/lib/tftpboot/centos7/root 10.19.20.0/24(rw,no_root_squash)
# systemctl start rpcbind nfs-server 
# systemctl enable rpcbind nfs-server 
</code></pre><p>现在在网络中加入新的机器，从PXE启动后，将直接进入到CentOS7的桌面。</p></div><div class=post><h1 class=post-title><a href=http://purplepalmdash.github.io/2016/06/07/rackhd-worktips/>RackHD Worktips</a></h1><span class=post-date>Jun 7, 2016<br><a class=a_cat href=http://purplepalmdash.github.io/categories/technology>Technology</a></span><h3 id=vagrant-preparation>Vagrant Preparation</h3><p>rackhd/rackhd vagrant box could be downloaded from following link:</p><p><a href=https://atlas.hashicorp.com/rackhd/boxes/rackhd>https://atlas.hashicorp.com/rackhd/boxes/rackhd</a></p><p>Clone the repository from the github:</p><pre><code>$ pwd
/home/dash/Code/Jun13
$ git clone https://github.com/RackHD/RackHD
$ cd RackHD
</code></pre><p>Change into the directory example, create config and run the setup command:</p><pre><code>$ cd example
$ cp config/monorail_rack.cfg.example config/monorail_rack.cfg
</code></pre><p>Edits can be made to this new file to adjust the number of pxe clients created.</p><pre><code>$ bin/monorail_rack
</code></pre><p>The <code>monorail_rack</code> script will auto-start all of the services by default, but you can also run them manually if you prefer.</p><pre><code>$ vagrant ssh
vagrant:~$ sudo nf start
</code></pre><p>Unfortunately, the vagrant machine won&rsquo;t work due to bad networking.</p><h3 id=customization-deployment>Customization Deployment</h3><p>Use a trusty based vagrant box for creating the rackhd node.</p><pre><code>$ vagrant init trustyvirtualbox
$ vim Vagrantfile
</code></pre><p>Vagrantfile&rsquo;s configuration modification is listed as following:</p><pre><code>Vagrant.configure(2) do |config|
  # The most common configuration options are documented and commented below.
  # For a complete reference, please see the online documentation at
  # https://docs.vagrantup.com.

  # Added more disks
+   file_to_disk = File.realpath( &quot;.&quot; ).to_s + &quot;/disk.vdi&quot;

  # config.vm.network &quot;private_network&quot;, ip: &quot;192.168.33.10&quot;
+   config.vm.network &quot;private_network&quot;, ip: &quot;172.31.128.1&quot;, virtualbox__intnet:  &quot;closednet&quot;

+  config.vm.provider &quot;virtualbox&quot; do |vb|
+    if ARGV[0] == &quot;up&quot; &amp;&amp; ! File.exist?(file_to_disk) 
+      puts &quot;Creating 5GB disk #{file_to_disk}.&quot;
+      vb.customize [
+        'createhd', 
+        '--filename', file_to_disk, 
+        '--format', 'VDI', 
+        '--size', 5000 * 1024 # 5 GB
+      ] 
+      vb.customize [
+        'storageattach', :id, 
+        '--storagectl', 'IDE Controller', 
+        '--port', 1, '--device', 0, 
+        '--type', 'hdd', '--medium', 
+        file_to_disk
+      ] 
+    end
+    vb.memory = &quot;4096&quot;
+    vb.cpus = 2
+    vb.customize [&quot;modifyvm&quot;, :id, &quot;--nicpromisc2&quot;, &quot;allow-all&quot;, &quot;--ioapic&quot;, &quot;on&quot;]
+  end
</code></pre><p>Then <code>vagrant up</code> for start up the machine.</p><p>Notice: the controller of the disk should be noticed very carefully, you could choose
&ldquo;IDE Controller&rdquo; Or &ldquo;SATA Controller&rdquo;, depending on your virtualbox configuration.<br>Then follow the tips on:</p><p><a href=http://purplepalmdash.github.io/blog/2016/06/01/use-rakehd-for-deploying-systems/>http://purplepalmdash.github.io/blog/2016/06/01/use-rakehd-for-deploying-systems/</a><br>Extend the root partition of vagrant disk via:</p><pre><code>$ sudo pvcreate /dev/sdb
$ sudo vgextend vagrant-vg /dev/sdb
$ sudo lvextend -l +100%FREE /dev/vagrant-vg/root
$ sudo resize2fs  /dev/vagrant-vg/root
</code></pre><h3 id=adding-ubuntu-deployment>Adding Ubuntu Deployment</h3><p>Install <code>apt-mirror</code> first, then using following mirror configuration file:</p><pre><code>$ vim /etc/apt/mirror.list
############# config ##################
#
# set base_path    /var/spool/apt-mirror
#
# set mirror_path  $base_path/mirror
# set skel_path    $base_path/skel
# set var_path     $base_path/var
# set cleanscript $var_path/clean.sh
# set defaultarch  &lt;running host architecture&gt;
# set postmirror_script $var_path/postmirror.sh
# set run_postmirror 0
set base_path	/var/mirrors/ubuntu/14.04
set nthreads     20
set _tilde 0
#
############# end config ##############

deb-amd64 http://mirrors.aliyun.com/ubuntu	trusty main main/debian-installers
deb http://mirrors.aliyun.com/ubuntu	trusty main/installer-amd64
deb-amd64 http://mirrors.aliyun.com/ubuntu	trusty-updates main
deb-amd64 http://mirrors.aliyun.com/ubuntu	trusty-security main
clean http://mirrors.aliyun.com/ubuntu
</code></pre><p>Also you have to create following script for downloading the debian-installer:</p><pre><code>$ vim /var/mirrors/ubuntu/14.04/var/postmirror.sh 
#!/bin/sh -x 
# the udebs script gets the actual files we need 
#/mnt/repo/apt-mirror/var/udebs.sh  
# A quick apt directory structure primer: 
# an apt server (e.g. archive.ubuntu.com) contains repositories (e.g. trusty-backports), 
# which contain archives (e.g. multiverse), which contain directories 
# a complete example - http://archive.ubuntu.com/ubuntu/dists/trusty-backports/multiverse/debian-installer/  
# With this in mind, we create bash 'arrays' of the structure: 
# server we're syncing against 
#MIRROR=&quot;cn.archive.ubuntu.com&quot; 
MIRROR=&quot;archive.ubuntu.com&quot; 
# repositories we're mirroring 
#REPOS=&quot;trusty trusty-updates trusty-security trusty-proposed trusty-backports&quot; 
REPOS=&quot;trusty&quot;
# archives in repositories 
#ARCHIVES=&quot;main multiverse restricted universe&quot; 
ARCHIVES=&quot;main&quot;
# installer location inside archive 
#DIRECTORIES=&quot;debian-installer dist-upgrader-all installer-amd64 installer-i386&quot; 
DIRECTORIES=&quot;debian-installer installer-amd64&quot;
#where we're storing it locally 
LOCALDIR=&quot;/var/mirrors/ubuntu/14.04/mirror/mirrors.aliyun.com&quot;
#LOCALDIR=&quot;/mnt/repo/apt-mirror/mirror/archive.ubuntu.com&quot;  
for REPO in $REPOS; do 
for ARCHIVE in $ARCHIVES; do 
for DIRECTORY in $DIRECTORIES;do 
# create directory structure 
if [ ! -e &quot;$LOCALDIR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY&quot; ]; then
mkdir -p &quot;$LOCALDIR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY&quot;
fi
# do the sync 
rsync --recursive --times --links --hard-links --delete --delete-after \
rsync://$MIRROR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY/ $LOCALDIR/ubuntu/dists/$REPO/$ARCHIVE/$DIRECTORY
done
done
done
</code></pre><p>Now run <code>sudo apt-mirror</code> for syncing the repository to local storage.</p><p>Also create a shortcut to the repository in RackHD System:</p><pre><code>$ sudo ln -s /var/mirrors/ubuntu/14.04/mirror/mirrors.aliyun.com/ubuntu/ /opt/monorail/static/http/
</code></pre><p>Now restart the rackhd node, the ubuntu deployment is ready for use.</p><h3 id=ubuntu-deployment>Ubuntu Deployment</h3><p>Add the json file which holds the ubuntu deployment:</p><pre><code>$ pwd
/home/vagrant/RackHD/example
$ vim samples/ubuntu_boot.json 
{
    &quot;name&quot;: &quot;Graph.InstallUbuntu&quot;,
    &quot;options&quot;: {
        &quot;defaults&quot;: {
            &quot;obmServiceName&quot;: &quot;noop-obm-service&quot;
        },
        &quot;install-os&quot;: {
            &quot;repo&quot;: &quot;{{api.server}}/ubuntu&quot;,
            &quot;rootPassword&quot;: &quot;ubuntu&quot;,
            &quot;profile&quot;: &quot;install-trusty.ipxe&quot;,
            &quot;completionUri&quot;: &quot;renasar-ansible.pub&quot;
        }
    }
}
</code></pre><p>In fact the <code>rootPassword</code> is not ready for use, the real password after deployment
is <code>RackHDRocks!</code>.</p><p>Add one node(first you should make it pxed):</p><pre><code>$ curl -H &quot;Content-Type: application/json&quot; -X POST --data @samples/noop_body.json http://localhost:8080/api/1.1/nodes/575fce38d23ba028051b4711/obm
$ curl -H &quot;Content-Type: application/json&quot; -X POST --data @samples/ubuntu_boot.json http://localhost:8080/api/1.1/nodes/575fce38d23ba028051b4711/workflows
</code></pre><p>Then restart the machine, you will get it installing ubuntu.</p></div><ul class=pagination><li class=page-item><a href=/ class=page-link aria-label=First><span aria-hidden=true>&#171;&#171;</span></a></li><li class=page-item><a href=/page/121/ class=page-link aria-label=Previous><span aria-hidden=true>&#171;</span></a></li><li class=page-item><a class=page-link href=/>1</a></li><li class=page-item><a class=page-link href=/page/2/>2</a></li><li class=page-item><a class=page-link href=/page/3/>3</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/121/>121</a></li><li class="page-item active"><a class=page-link href=/page/122/>122</a></li><li class=page-item><a class=page-link href=/page/123/>123</a></li><li class="page-item disabled"><span aria-hidden=true>&nbsp;&mldr;&nbsp;</span></li><li class=page-item><a class=page-link href=/page/249/>249</a></li><li class=page-item><a href=/page/123/ class=page-link aria-label=Next><span aria-hidden=true>&#187;</span></a></li><li class=page-item><a href=/page/249/ class=page-link aria-label=Last><span aria-hidden=true>&#187;&#187;</span></a></li></ul></div></div><script src=http://purplepalmdash.github.io/js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad();</script></body></html>